{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import *\n",
    "from models import *\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "FIRST_RUN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Options:\n",
    "    def __init__(self):\n",
    "        self.model_name = 'alp'\n",
    "\n",
    "options = Options()\n",
    "options.output_file = 'test_output/reapos_test_text.txt'\n",
    "options.params_file = 'params-v1.yaml'\n",
    "options.use_cuda = False\n",
    "options.use_validation = True\n",
    "options.gpu2cpu = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use cuda: False\n",
      "Input punc lvl:  1\n",
      "Output punc lvl:  2\n"
     ]
    }
   ],
   "source": [
    "#LOAD CONFIGURATIONS AND LANGUAGES\n",
    "USE_CUDA = options.use_cuda\n",
    "print(\"Use cuda: %s\" %USE_CUDA)\n",
    "\n",
    "try:\n",
    "    with open(options.params_file, 'r') as ymlfile:\n",
    "        config = yaml.load(ymlfile)\n",
    "except:\n",
    "    sys.exit(\"Parameters file missing\")\n",
    "\n",
    "#Setup languages\n",
    "INPUT_LANG_CODE = config['INPUT_LANG']\n",
    "OUTPUT_LANG_CODE = config['OUTPUT_LANG']\n",
    "\n",
    "INPUT_LANG_PUNC_LEVEL = config[\"INPUT_LANG_PUNC_LEVEL\"]\n",
    "OUTPUT_LANG_PUNC_LEVEL = config[\"OUTPUT_LANG_PUNC_LEVEL\"]\n",
    "\n",
    "INPUT_LANG_PUNC_LEVEL = 1\n",
    "OUTPUT_LANG_PUNC_LEVEL = 2\n",
    "\n",
    "print('Input punc lvl: ', INPUT_LANG_PUNC_LEVEL)\n",
    "print('Output punc lvl: ', OUTPUT_LANG_PUNC_LEVEL)\n",
    "\n",
    "if FIRST_RUN: \n",
    "    if INPUT_LANG_CODE == 'en' and OUTPUT_LANG_CODE == 'es':\n",
    "        lang_en = input_lang = Lang(INPUT_LANG_CODE, config[\"W2V_EN_PATH\"], config[\"DICT_EN_PATH\"], punctuation_level=INPUT_LANG_PUNC_LEVEL)\n",
    "        lang_es = output_lang = Lang(OUTPUT_LANG_CODE, config[\"W2V_ES_PATH\"], config[\"DICT_ES_PATH\"], punctuation_level=OUTPUT_LANG_PUNC_LEVEL)\n",
    "    elif INPUT_LANG_CODE == 'es' and OUTPUT_LANG_CODE == 'en':\n",
    "        lang_es = input_lang = Lang(INPUT_LANG_CODE, config[\"W2V_ES_PATH\"], config[\"DICT_ES_PATH\"], punctuation_level=INPUT_LANG_PUNC_LEVEL)\n",
    "        lang_en = output_lang = Lang(OUTPUT_LANG_CODE, config[\"W2V_EN_PATH\"], config[\"DICT_EN_PATH\"], punctuation_level=OUTPUT_LANG_PUNC_LEVEL)\n",
    "    FIRST_RUN = False\n",
    "\n",
    "input_prosody_params = config['INPUT_PROSODY']\n",
    "if input_prosody_params == None:\n",
    "    input_prosody_params = []\n",
    "output_prosody_params = config['OUTPUT_PROSODY']\n",
    "if output_prosody_params == None:\n",
    "    output_prosody_params = []    \n",
    "    \n",
    "#NETWORK CONFIG\n",
    "max_seq_length = int(config['MAX_SEQ_LENGTH'])\n",
    "n_prosody_params = int(config['N_PROSODY_PARAMS'])\n",
    "input_prosody_params = config['INPUT_PROSODY']\n",
    "encoder_type = config['ENCODER_TYPE']\n",
    "attn_model = config['ATTN_MODEL']\n",
    "hidden_size = int(config['HIDDEN_SIZE'])\n",
    "n_layers = int(config['N_LAYERS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUDIO_TEST_DATA_PATH /Users/alp/Movies/heroes/transProse_data/audiodata-v1/transProse_audiodata_test.txt\n"
     ]
    }
   ],
   "source": [
    "#LOAD DATASETS PATHS\n",
    "AUDIO_TEST_DATA_PATH = config[\"AUDIO_TEST_DATA_FILE\"]\n",
    "AUDIO_TRAIN_DATA_PATH = config[\"AUDIO_TRAIN_DATA_FILE\"]\n",
    "AUDIO_VALIDATION_DATA_PATH = config[\"AUDIO_VALIDATION_DATA_FILE\"]\n",
    "TEXT_TEST_DATA_PATH = config['TEXT_TEST_DATA_PATH']\n",
    "AUDIO_ALL_DATA_PATH = \"/Users/alp/Movies/heroes/transProse_data/audiodata-v1/transProse_audiodata.txt\"\n",
    "AUDIO_SIGNIFICANT_TEST_DATA_PATH = \"/Users/alp/Movies/heroes/transProse_data/audiodata-v2/transProse_audiodata-v2_test_pausesignificant.txt\"\n",
    "AUDIO_PUNKPROSED_TEST_V1_DATA_PATH = \"/Users/alp/Movies/heroes/transProse_data/audiodata-v1/transProse_audiodata_test_punkProsed.txt\"\n",
    "AUDIO_PUNKPROSED_TEST_V2_DATA_PATH = \"/Users/alp/Movies/heroes/transProse_data/audiodata-v2/transProse_audiodata-v2_test_punkProsed.txt\"\n",
    "AUDIO_PUNKPROSED_TEST_NEW_DATA_PATH = \"/Users/alp/Movies/heroes/transProse_data/audiodata-new/transProse_heroes_new_audiodata_test_punkProsed.txt\"\n",
    "\n",
    "print(\"AUDIO_TEST_DATA_PATH\", AUDIO_TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input punc lvl:  2\n",
      "Output punc lvl:  2\n",
      "gpu2cpu: True\n"
     ]
    }
   ],
   "source": [
    "#Initialize text models\n",
    "# text_encoder_path = 'models/5mmheroes_puncdinput_encoder.model'\n",
    "# text_decoder_path = 'models/5mmheroes_puncdinput_decoder.model'\n",
    "\n",
    "text_encoder_path = 'models/5mmheroes_puncdinput_encoder.model'\n",
    "text_decoder_path = 'models/5mmheroes_puncdinput_decoder.model'\n",
    "\n",
    "print('Input punc lvl: ', INPUT_LANG_PUNC_LEVEL)\n",
    "print('Output punc lvl: ', OUTPUT_LANG_PUNC_LEVEL)\n",
    "\n",
    "text_encoder = GenericEncoder(input_lang.vocabulary_size, hidden_size, input_lang.get_weights_matrix(), n_layers)\n",
    "text_decoder = LuongAttnDecoderRNN(attn_model, hidden_size, output_lang.get_weights_matrix(), output_lang.vocabulary_size, n_layers, input_feed=config['DECODER_INPUT_FEED'])\n",
    "load_model(text_encoder, text_decoder, text_encoder_path, text_decoder_path, options.gpu2cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUDIO_ENCODE_ONLY\n",
      "gpu2cpu: True\n"
     ]
    }
   ],
   "source": [
    "#Initialize prosodic models\n",
    "AUDIO_ENCODE_ONLY = True\n",
    "model_name = \"audio_punctuatedin-v1\"\n",
    "prosodic_encoder_path = 'models/' + model_name + '_encoder.model'\n",
    "prosodic_decoder_path = 'models/' + model_name + '_decoder.model'\n",
    "\n",
    "if encoder_type == 'sum':\n",
    "    prosodic_encoder = EncoderRNN_sum_ver(input_lang.vocabulary_size, n_prosody_params, hidden_size, input_lang.get_weights_matrix(), n_layers)\n",
    "elif encoder_type == 'parallel':\n",
    "    prosodic_encoder = EncoderRNN_parallel(input_lang.vocabulary_size, n_prosody_params, hidden_size, input_lang.get_weights_matrix(), n_layers)\n",
    "else:\n",
    "    sys.exit(\"Unrecognized encoder type. Check params file. Exiting...\")\n",
    "if AUDIO_ENCODE_ONLY:\n",
    "    print(\"AUDIO_ENCODE_ONLY\")\n",
    "    prosodic_decoder = LuongAttnDecoderRNN(attn_model, hidden_size, output_lang.get_weights_matrix(), output_lang.vocabulary_size, n_layers, USE_CUDA=USE_CUDA)\n",
    "else:\n",
    "    prosodic_decoder = ProsodicDecoderRNN(attn_model, hidden_size, output_lang.get_weights_matrix(), output_lang.vocabulary_size, n_layers, USE_CUDA=USE_CUDA)\n",
    "    \n",
    "load_model(prosodic_encoder, prosodic_decoder, prosodic_encoder_path, prosodic_decoder_path, gpu_to_cpu=options.gpu2cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA GENERATORS\n",
    "#generates data from tab separated file\n",
    "def text_data_generator(data_path, input_lang, output_lang, stop_at=-1):\n",
    "    count = 0\n",
    "    with open(data_path,'r') as inputfile:\n",
    "        for line in inputfile:\n",
    "            if not stop_at == -1 and count >= stop_at:\n",
    "                break\n",
    "            pair = [sentence.strip() for sentence in line.split('\\t')]\n",
    "            if input_lang.lang_code == 'en':\n",
    "                in_sentence = pair[0]\n",
    "                out_sentence = pair[1]\n",
    "            elif input_lang.lang_code == 'es':\n",
    "                in_sentence = pair[1]\n",
    "                out_sentence = pair[0]\n",
    "\n",
    "            in_sentence_tokens = in_sentence.lower().split()\n",
    "            out_sentence_tokens = out_sentence.lower().split()\n",
    "\n",
    "            if input_lang.punctuation_level == 0:\n",
    "                in_sentence_tokens = remove_punc_tokens(in_sentence_tokens)\n",
    "            elif input_lang.punctuation_level == 1:\n",
    "                in_sentence_tokens = remove_punc_tokens(in_sentence_tokens, keep_main_puncs=True)\n",
    "            if output_lang.punctuation_level == 0:\n",
    "                out_sentence_tokens = remove_punc_tokens(out_sentence_tokens)\n",
    "            elif output_lang.punctuation_level == 1:\n",
    "                out_sentence_tokens = remove_punc_tokens(out_sentence_tokens, keep_main_puncs=True)\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            yield in_sentence_tokens, out_sentence_tokens       \n",
    "            \n",
    "def audio_data_generator(data_path, input_lang, output_lang, n_prosody_params, input_prosody_params, output_prosody_params, dummyfy_input_prosody=False, dummyfy_output_prosody=False, stop_at = -1):\n",
    "    assert not input_lang == output_lang\n",
    "    audio_data = read_audio_dataset_file(data_path, shuffle=False)\n",
    "\n",
    "    #start generating samples from the proscript links in the data file\n",
    "    count = 0\n",
    "    for segment_data in audio_data:\n",
    "        if not stop_at == -1 and count >= stop_at:\n",
    "            break\n",
    "\n",
    "        es_txt = segment_data[0]\n",
    "        es_csv = segment_data[1]\n",
    "        en_txt = segment_data[2]\n",
    "        en_csv = segment_data[3]\n",
    "        \n",
    "        #print(en_csv)\n",
    "        #print(es_csv)\n",
    "\n",
    "        if input_lang.lang_code == 'en' and output_lang.lang_code == 'es':\n",
    "            input_proscript = en_csv\n",
    "            output_proscript = es_csv\n",
    "            #input_transcript = read_text_file(en_txt)\n",
    "            #output_transcript = read_text_file(es_txt)\n",
    "        elif input_lang.lang_code == 'es' and output_lang.lang_code == 'en':\n",
    "            input_proscript = es_csv\n",
    "            output_proscript = en_csv\n",
    "            #input_transcript = read_text_file(es_txt)\n",
    "            #output_transcript = read_text_file(en_txt)\n",
    "            \n",
    "        if input_lang.punctuation_level == 0:\n",
    "            input_punc = False\n",
    "            input_only_main_punc = False\n",
    "        elif input_lang.punctuation_level == 1:\n",
    "            input_punc = True\n",
    "            input_only_main_punc = True\n",
    "        elif input_lang.punctuation_level == 2:\n",
    "            input_punc = True\n",
    "            input_only_main_punc = False\n",
    "            \n",
    "        if output_lang.punctuation_level == 0:\n",
    "            output_punc = False\n",
    "            output_only_main_punc = False\n",
    "        elif output_lang.punctuation_level == 1:\n",
    "            output_punc = True\n",
    "            output_only_main_punc = True\n",
    "        elif output_lang.punctuation_level == 2:\n",
    "            output_punc = True\n",
    "            output_only_main_punc = False\n",
    "\n",
    "        in_sentence_tokens, in_prosody_tokens = read_data_from_proscript(input_proscript, input_lang, n_prosody_params, input_prosody_params, punctuation_as_tokens = input_punc, keep_only_main_puncs = input_only_main_punc)\n",
    "        out_sentence_tokens, out_prosody_tokens = read_data_from_proscript(output_proscript, output_lang, n_prosody_params, output_prosody_params, punctuation_as_tokens = output_punc, keep_only_main_puncs = output_only_main_punc)\n",
    "    \n",
    "        if dummyfy_input_prosody:\n",
    "            in_prosody_tokens = np.zeros_like(in_prosody_tokens)\n",
    "        if dummyfy_output_prosody:\n",
    "            out_prosody_tokens = np.zeros_like(out_prosody_tokens)\n",
    "            \n",
    "        count += 1\n",
    "        yield in_sentence_tokens, in_prosody_tokens, out_sentence_tokens, out_prosody_tokens, en_csv, es_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#various utilities\n",
    "def print_prosody(prosody):\n",
    "    print(np.array(prosody).transpose())\n",
    "    \n",
    "def print_tokens_with_pause(tokens, pausevals = [], pauseflags=[], ssml_format=False, min_pause_duration=0.0):\n",
    "    if pauseflags == [] and not pausevals == []:\n",
    "        pauseflags = flags_from_value(pausevals)\n",
    "        \n",
    "    to_print = \"\"\n",
    "    for i, token in enumerate(tokens):\n",
    "        if not token == \"END\":\n",
    "            to_print += token + \" \"\n",
    "            if not pauseflags == [] and pauseflags[i]:\n",
    "                pause_to_print = \"\"    \n",
    "                if not ssml_format:\n",
    "                    pause_to_print += \"[P]\"\n",
    "                if not pausevals == []:\n",
    "                    if pausevals[i] > min_pause_duration:\n",
    "                        if ssml_format:\n",
    "                            pause_to_print += '<break time=\"%ims\"/>'%(pausevals[i]*1000)\n",
    "                else:\n",
    "                    if ssml_format:\n",
    "                        pause_to_print += '<break time=\"0000ms\"/>'\n",
    "                \n",
    "                to_print += pause_to_print + \" \"\n",
    "            \n",
    "    #print(to_print)\n",
    "    return to_print\n",
    "            \n",
    "def flags_from_value(prosody_seq):\n",
    "    return [1 if not feature_value == 0.0 else 0 for feature_value in prosody_seq]\n",
    "\n",
    "def show_attention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEE TEXT DATA\n",
    "for in_sent, out_sent in text_data_generator(TEXT_TEST_DATA_PATH, input_lang, output_lang):\n",
    "    print(in_sent)\n",
    "    print(out_sent)\n",
    "    exit = input('...')\n",
    "    if exit == 'q':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alp/Movies/heroes/corpus/heroes_s3_12/spa-eng/segments_eng/heroes_s3_12_eng_aligned_eng0124.csv\n",
      "['it', \"'s\", 'all', 'right', ',', 'scott', '.']\n",
      "[10, 9, 42, 63, 1, 1797, 0, 29998]\n",
      "[[ 0.      0.      0.      0.03    0.      0.      0.      0.    ]\n",
      " [-1.2936 -1.2936 -1.2936  2.1312  2.1312  0.2578  0.2578  0.    ]\n",
      " [ 0.0284  0.0284  0.0284  2.3402  2.3402  0.8338  0.8338  0.    ]]\n",
      "['¿', 'qué', 'lleva', 'eso', '?']\n",
      "[[0.     0.8    0.     0.     0.    ]\n",
      " [0.     0.     4.113  3.0542 3.0542]\n",
      " [0.     0.     0.667  0.1085 0.1085]]\n"
     ]
    }
   ],
   "source": [
    "#SEE AUDIO DATA\n",
    "max_f0 = 0.0\n",
    "min_f0 = 0.0\n",
    "\n",
    "input_prosody_params = ['pause_after', 'f0_mean', 'i0_mean']\n",
    "output_prosody_params = ['pause_after', 'f0_mean', 'i0_mean']\n",
    "n_prosody_params = 3\n",
    "data_path = AUDIO_VALIDATION_DATA_PATH\n",
    "for in_sent, in_pros, out_sent, out_pros, in_csv, out_csv in audio_data_generator(data_path, input_lang, output_lang, n_prosody_params, input_prosody_params, output_prosody_params, dummyfy_input_prosody=False, dummyfy_output_prosody=False):\n",
    "    if 'scott' in in_sent:\n",
    "        print(in_csv)\n",
    "        print(in_sent)\n",
    "        print(indexes_from_tokens(input_lang, in_sent))\n",
    "        in_pros = finalize_prosody_sequence(in_pros)\n",
    "        print_prosody(in_pros)\n",
    "        print(out_sent)\n",
    "        print_prosody(out_pros)\n",
    "#     print(os.path.basename(in_csv).split('.')[0] + '.wav')\n",
    "#     in_string = print_tokens_with_pause(in_sent)\n",
    "#     print(in_string)\n",
    "#     gt_string = print_tokens_with_pause(out_sent, out_pros[:,0], ssml_format=True, min_pause_duration = 0.05)\n",
    "#     gt_string = print_tokens_with_pause(out_sent)\n",
    "#     print(gt_string)\n",
    "    \n",
    "#     rt = os.path.splitext(os.path.basename(in_csv))[0]\n",
    "#     ppd = rt + \"_punkProsed.csv\"\n",
    "#     full_ppd = os.path.join(path, ppd)\n",
    "#     print(\"_\\t%s\\t_\\t%s\"%(out_csv, full_ppd))\n",
    "\n",
    "#     print(\"%s\\t%s\"%(' '.join(in_sent), ' '.join(out_sent)))\n",
    "    \n",
    "        exit = input('...')\n",
    "        if exit == 'q':\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUATORS\n",
    "#text -> text\n",
    "def evaluate_text(input_seq_tokens, input_lang, output_lang, encoder, decoder, max_length, USE_CUDA=False):\n",
    "    input_word_seqs = [indexes_from_tokens(input_lang, input_seq_tokens)]\n",
    "    \n",
    "    #make sure sequences are below max_length. \n",
    "    input_word_seqs = limit_seqs_to_max(input_word_seqs, max_length)\n",
    "\n",
    "    input_lengths = [len(input_word_seqs[0])]\n",
    "    input_word_batch = Variable(torch.LongTensor(input_word_seqs)).transpose(0, 1)\n",
    "\n",
    "    if USE_CUDA:\n",
    "        input_word_batch = input_batch.cuda()\n",
    "        input_prosody_batch = input_prosody_batch.cuda()\n",
    "\n",
    "    # Set to not-training mode to disable dropout\n",
    "    encoder.train(False)\n",
    "    decoder.train(False)\n",
    "\n",
    "    # Run through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_word_batch, input_lengths, None)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = Variable(torch.LongTensor([output_lang.token2index(SWT_TOKEN)])) # SOS\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
    "\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "        decoder_context = decoder_context.cuda()\n",
    "\n",
    "    # Store output words and attention states\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length + 1, max_length + 1)\n",
    "\n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_context, decoder_hidden, decoder_attn = decoder(\n",
    "                decoder_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "        \n",
    "        decoder_attentions[di,:decoder_attn.size(2)] += decoder_attn.squeeze(0).squeeze(0).cpu().data\n",
    "\n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        #ni = topi[0][0]  #old code\n",
    "        ni = topi.item()\n",
    "        if ni == output_lang.token2index(EOS_TOKEN):\n",
    "            decoded_words.append(EOS_TOKEN)\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2token(ni))\n",
    "\n",
    "        # Next input is chosen word\n",
    "        decoder_input = Variable(torch.LongTensor([ni]))\n",
    "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Set back to training mode\n",
    "    encoder.train(True)\n",
    "    decoder.train(True)\n",
    "\n",
    "    return decoded_words, decoder_attentions[:di+1, :len(encoder_outputs)]\n",
    "\n",
    "#text+audio -> text+audio\n",
    "#use prosodic encoder/decoder\n",
    "def evaluate_audio(input_seq_tokens, input_prosody_tokens, input_lang, output_lang, encoder, decoder, max_length, audio_encode_only, USE_CUDA=False):\n",
    "    input_word_seqs = [indexes_from_tokens(input_lang, input_seq_tokens)]\n",
    "    input_prosody_seqs = [finalize_prosody_sequence(input_prosody_tokens)] #put the end token\n",
    "    \n",
    "    #make sure sequences are below max_length. \n",
    "    input_word_seqs = limit_seqs_to_max(input_word_seqs, max_length)\n",
    "    input_prosody_seqs = limit_seqs_to_max(input_prosody_seqs, max_length)\n",
    "\n",
    "    input_lengths = [len(input_word_seqs[0])]\n",
    "    input_word_batch = Variable(torch.LongTensor(input_word_seqs)).transpose(0, 1)\n",
    "    input_prosody_batch = Variable(torch.FloatTensor(input_prosody_seqs)).transpose(0, 1)\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        input_word_batch = input_batch.cuda()\n",
    "        input_prosody_batch = input_prosody_batch.cuda()\n",
    "\n",
    "    # Set to not-training mode to disable dropout\n",
    "    encoder.train(False)\n",
    "    decoder.train(False)\n",
    "\n",
    "    # Run through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_word_batch, input_prosody_batch, input_lengths, None)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_word_input = Variable(torch.LongTensor([output_lang.token2index(SWT_TOKEN)])) # SOS\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
    "    decoder_context = Variable(torch.zeros(1, decoder.hidden_size))\n",
    "\n",
    "    if USE_CUDA:\n",
    "        decoder_word_input = decoder_word_input.cuda()\n",
    "        decoder_context = decoder_context.cuda()\n",
    "\n",
    "    # Store output words and attention states\n",
    "    decoded_word_seq = []\n",
    "    decoded_pauseflag_seq = []\n",
    "    decoded_pausevalue_seq = []\n",
    "    decoder_attentions = torch.zeros(max_length + 1, max_length + 1)\n",
    "\n",
    "    # Run through decoder\n",
    "    decoder_stop = False\n",
    "    for di in range(max_length):\n",
    "        if audio_encode_only:\n",
    "            decoder_output_word, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_word_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "        else:\n",
    "#             decoder_output_word, decoder_output_pauseflag, decoder_output_pausevalue, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "#                 decoder_word_input, decoder_context, decoder_hidden, encoder_outputs\n",
    "#             )  #FLAGTEST\n",
    "            \n",
    "            decoder_output_word, decoder_output_pauseflag, decoder_context, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_word_input, decoder_context, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "        \n",
    "        decoder_attentions[di,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "            \n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_output_word.data.topk(1)\n",
    "        ni_word = topi.item()\n",
    "        if ni_word == output_lang.token2index(EOS_TOKEN):\n",
    "            decoded_word_seq.append(EOS_TOKEN)\n",
    "            decoder_stop = True\n",
    "        else:\n",
    "            decoded_word_seq.append(output_lang.index2token(ni_word))\n",
    "        \n",
    "        if not audio_encode_only:\n",
    "            # Look at pauseflag output\n",
    "            topv, topi = decoder_output_pauseflag.data.topk(1)\n",
    "            ni_pauseflag = topi.item()\n",
    "            decoded_pauseflag_seq.append(ni_pauseflag)\n",
    "\n",
    "            # Look at pauseval output\n",
    "            #predicted_pausevalue = decoder_output_pausevalue.item()\n",
    "            #decoded_pausevalue_seq.append(unnormalize_value(predicted_pausevalue, 0.0, 10.0))\n",
    "            #decoded_pausevalue_seq.append(predicted_pausevalue)\n",
    "\n",
    "        # Next input is chosen word\n",
    "        if decoder_stop:\n",
    "            break\n",
    "        else:\n",
    "            decoder_word_input = Variable(torch.LongTensor([ni_word]))\n",
    "            if USE_CUDA: decoder_word_input = decoder_word_input.cuda()\n",
    "\n",
    "    # Set back to training mode\n",
    "    encoder.train(True)\n",
    "    decoder.train(True)\n",
    "\n",
    "    #return decoded_word_seq, decoded_pauseflag_seq, decoded_pausevalue_seq, decoder_attentions[:di+1, :len(encoder_outputs)]  #FLAGTEST\n",
    "    return decoded_word_seq, decoded_pauseflag_seq, decoder_attentions[:di+1, :len(encoder_outputs)]  #FLAGTEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text -> text evaluator test\n",
    "input_sentence = \"he 's flying through that glass ?\" \n",
    "input_seq_tokens = input_sentence.split()\n",
    "decoded_words, attentions = evaluate_text(input_seq_tokens, input_lang, output_lang, text_encoder, text_decoder, max_seq_length)\n",
    "print(readable_from_tokens(decoded_words[:-1]))\n",
    "show_attention(input_sentence, decoded_words, attentions)\n",
    "#print(attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_attention(readable_from_tokens(in_sentence_tokens), translation_tokens, attentions)\n",
    "print(attentions.shape)\n",
    "print(attentions[0])\n",
    "print(np.argmax(attentions[0]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prosodic evaluator test\n",
    "input_proscript = '/Users/alp/Movies/heroes/corpus/heroes_s2_7/spa-eng/segments_eng/heroes_s2_7_eng_aligned_eng0278.csv'\n",
    "in_sentence_tokens, in_prosody_tokens = read_data_from_proscript(input_proscript, input_lang, n_prosody_params, input_prosody_params)\n",
    "\n",
    "translation_tokens, pauseflag_tokens, attentions = evaluate_audio(in_sentence_tokens, in_prosody_tokens, input_lang, output_lang, prosodic_encoder, prosodic_decoder, max_seq_length, audio_encode_only=AUDIO_ENCODE_ONLY)\n",
    "prosody_translation_string = print_tokens_with_pause(translation_tokens, pauseflags=pauseflag_tokens, ssml_format=True)\n",
    "    \n",
    "translation_tokens, _ = evaluate_text(in_sentence_tokens, input_lang, output_lang, text_encoder, text_decoder, max_seq_length)\n",
    "text_translation_string = print_tokens_with_pause(translation_tokens)\n",
    "\n",
    "print('---input audio---')\n",
    "in_sentence_string = print_tokens_with_pause(in_sentence_tokens, in_prosody_tokens[:,0])\n",
    "print(in_sentence_string)\n",
    "\n",
    "print('---text translation---')\n",
    "print(text_translation_string)\n",
    "\n",
    "print('---prosodic translation---')\n",
    "print(prosody_translation_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded /Users/alp/Movies/heroes/transProse_data/audiodata-v1/transProse_audiodata_test.txt\n"
     ]
    }
   ],
   "source": [
    "data_path = AUDIO_TEST_DATA_PATH\n",
    "gen = audio_data_generator(AUDIO_TEST_DATA_PATH, input_lang, output_lang, n_prosody_params, input_prosody_params, output_prosody_params)\n",
    "print(\"Loaded\", data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alp/Movies/heroes/corpus/heroes_s2_1/spa-eng/segments_eng/heroes_s2_1_eng_aligned_eng0012.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alp/extSW/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:6: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that they are bound together by a common purpose ? \n",
      "¿ que se van a hacer un propósito propósito ? \n",
      "¿ que se van a un propósito propósito ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_1/spa-eng/segments_eng/heroes_s2_1_eng_aligned_eng0137.csv\n",
      "now <break time=\"1080ms\"/> , who said this ? \n",
      "¿ quién ha dicho esto ? \n",
      "¿ quién ha dicho esto ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_1/spa-eng/segments_eng/heroes_s2_1_eng_aligned_eng0254.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alp/extSW/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:17: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "why would you ask me that ? \n",
      "¿ por qué me preguntas eso ? \n",
      "¿ por qué me lo preguntas ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_1/spa-eng/segments_eng/heroes_s2_1_eng_aligned_eng0327.csv\n",
      "don 't  go , please . \n",
      "no te vayas , por favor . \n",
      "no te vayas , por favor . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_1/spa-eng/segments_eng/heroes_s2_1_eng_aligned_eng0361.csv\n",
      "no <break time=\"660ms\"/> . this can 't be . \n",
      "no <break time=\"0000ms\"/> . esto no puede ser . \n",
      "no . no . esto no puede ser . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_1/spa-eng/segments_eng/heroes_s2_1_eng_aligned_eng0386.csv\n",
      "i suggest you <break time=\"410ms\"/> disappear as well . \n",
      "te sugiero que desaparezcas en tu vida . \n",
      "te sugiero desaparecer como mejor . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_1/spa-eng/segments_eng/heroes_s2_1_eng_aligned_eng0444.csv\n",
      "my <break time=\"70ms\"/> god my  god <break time=\"820ms\"/> , what have  i <break time=\"120ms\"/> done ? \n",
      "dios mío dios , ¿ qué he hecho ? \n",
      "dios mío , ¿ qué he hecho ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_1/spa-eng/segments_eng/heroes_s2_1_eng_aligned_eng0450.csv\n",
      "i  don 't know . i 'm  not sure . \n",
      "no lo sé <break time=\"0000ms\"/> . no estoy seguro . \n",
      "no lo sé . no lo sé . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_10/spa-eng/segments_eng/heroes_s2_10_eng_aligned_eng0012.csv\n",
      "when i get my ability back , i 'm gonna kill you  and your sister . \n",
      "cuando vuelva mi poder , te mataré a ti y tu hermana . \n",
      "cuando vuelva mi poder , te mataré y a tu hermana . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_10/spa-eng/segments_eng/heroes_s2_10_eng_aligned_eng0022.csv\n",
      "what do you know about this virus ? \n",
      "¿ qué sabes de este virus ? \n",
      "¿ qué sabes de este virus ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_10/spa-eng/segments_eng/heroes_s2_10_eng_aligned_eng0137.csv\n",
      "but i need my brother . \n",
      "pero <break time=\"0000ms\"/> necesito a mi hermano . \n",
      "pero necesito a mi hermano . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_10/spa-eng/segments_eng/heroes_s2_10_eng_aligned_eng0180.csv\n",
      "are you all right , victoria ? \n",
      "¿ estás <break time=\"0000ms\"/> bien ? ¿ estás <break time=\"0000ms\"/> bien , victoria ? \n",
      "¿ estás bien , victoria ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_10/spa-eng/segments_eng/heroes_s2_10_eng_aligned_eng0216.csv\n",
      "i can control my  power . \n",
      "puedo controlar mi poder . \n",
      "puedo controlar mi poder . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_10/spa-eng/segments_eng/heroes_s2_10_eng_aligned_eng0247.csv\n",
      "i  am  not leaving you  alone with him . \n",
      "no te dejaré con él . \n",
      "no te abandonaré con él . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_10/spa-eng/segments_eng/heroes_s2_10_eng_aligned_eng0249.csv\n",
      "i killed the  woman you <break time=\"90ms\"/> loved . \n",
      "maté a la mujer que amabas . \n",
      "maté a la mujer que amaba . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_10/spa-eng/segments_eng/heroes_s2_10_eng_aligned_eng0278.csv\n",
      "we 're letting you go . \n",
      "te dejaremos . \n",
      "te dejaremos . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_10/spa-eng/segments_eng/heroes_s2_10_eng_aligned_eng0303.csv\n",
      "i 'm taking  my sister \n",
      "¡ voy a llevar a mi hermana ! \n",
      "¡ me voy a llevar a mi hermana ! \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_10/spa-eng/segments_eng/heroes_s2_10_eng_aligned_eng0398.csv\n",
      "this doesn 't look like the sort of place they 'd store a virus <break time=\"100ms\"/> that could destroy the world . \n",
      "esto no parece un virus de donde podría almacenar un virus que podría destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir \n",
      "no parece que el mundo de sitio que podría almacenar una virus para destruir un virus que podría destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir destruir \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_11/spa-eng/segments_eng/heroes_s2_11_eng_aligned_eng0016.csv\n",
      "why am i not dead ? \n",
      "¿ por qué no estoy muerto ? \n",
      "¿ por qué no estoy muerto ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_11/spa-eng/segments_eng/heroes_s2_11_eng_aligned_eng0114.csv\n",
      "he murdered my father . \n",
      "mató a mi padre . \n",
      "mató a mi padre . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_11/spa-eng/segments_eng/heroes_s2_11_eng_aligned_eng0147.csv\n",
      "i 'm stuck in this hellhole <break time=\"340ms\"/> . my family thinks i 'm dead . \n",
      "estoy en este lugar <break time=\"0000ms\"/> , mi familia cree que estoy muerto . \n",
      "estoy en este infierno , mi familia cree que estoy muerta . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_11/spa-eng/segments_eng/heroes_s2_11_eng_aligned_eng0160.csv\n",
      "leaving . \n",
      "se va . \n",
      "se va . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_11/spa-eng/segments_eng/heroes_s2_11_eng_aligned_eng0217.csv\n",
      "which i can use to triangulate her position . \n",
      "lo que puedo utilizar para transmitir su situación . \n",
      "lo que puedo utilizar para anular su situación . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_11/spa-eng/segments_eng/heroes_s2_11_eng_aligned_eng0398.csv\n",
      "you have no idea <break time=\"920ms\"/> how extraordinary . \n",
      "no tienes idea de lo que extraordinario . \n",
      "no tienes idea idea . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_2/spa-eng/segments_eng/heroes_s2_2_eng_aligned_eng0043.csv\n",
      "did you see <break time=\"520ms\"/> this ? \n",
      "¿ has visto esto ? \n",
      "¿ has visto esto ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_2/spa-eng/segments_eng/heroes_s2_2_eng_aligned_eng0081.csv\n",
      "but newts  are not the only creatures with this talent . \n",
      "pero no son los únicos con este talento . \n",
      "pero no los únicos son con este talento . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_2/spa-eng/segments_eng/heroes_s2_2_eng_aligned_eng0097.csv\n",
      "so <break time=\"90ms\"/> how 'd you like the jet ? \n",
      "¿ y cómo te gusta el avión ? \n",
      "¿ y cómo te gustó el avión ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_2/spa-eng/segments_eng/heroes_s2_2_eng_aligned_eng0163.csv\n",
      "my sister is not <break time=\"280ms\"/> well . we are <break time=\"460ms\"/> going to <break time=\"60ms\"/> get her medical help . \n",
      "mi hermana no es buena solución . vamos a buscar . \n",
      "mi hermana no va a ser bien . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_2/spa-eng/segments_eng/heroes_s2_2_eng_aligned_eng0207.csv\n",
      "you work for people ? \n",
      "¿ trabajas para personas ? \n",
      "¿ trabajas para personas ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_2/spa-eng/segments_eng/heroes_s2_2_eng_aligned_eng0255.csv\n",
      "then the one they 'd put you in . \n",
      "y luego te metiste . \n",
      "y luego te encerrarán . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_2/spa-eng/segments_eng/heroes_s2_2_eng_aligned_eng0256.csv\n",
      "i 've gotta get back to  work . \n",
      "debo volver a trabajar . \n",
      "tengo que volver a trabajar . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_2/spa-eng/segments_eng/heroes_s2_2_eng_aligned_eng0266.csv\n",
      "the most common motives are  money and sex . \n",
      "los demás son son dinero y sexo . \n",
      "los más de los motivos son dinero y sexo . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_3/spa-eng/segments_eng/heroes_s2_3_eng_aligned_eng0007.csv\n",
      "don 't worry . \n",
      "tranquilo . \n",
      "tranquilo . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_3/spa-eng/segments_eng/heroes_s2_3_eng_aligned_eng0033.csv\n",
      "that cash is mine . that cash is mine . \n",
      "ese dinero es mío . ese cheque es mío . \n",
      "ese es mío . ese es mi dinero . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_3/spa-eng/segments_eng/heroes_s2_3_eng_aligned_eng0307.csv\n",
      "my father <break time=\"230ms\"/> , ando <break time=\"740ms\"/> they are all waiting  for me . \n",
      "mi padre , me están esperando . \n",
      "mi padre , me esperan todos . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_3/spa-eng/segments_eng/heroes_s2_3_eng_aligned_eng0323.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i <break time=\"190ms\"/> thought you said you were taking care of me ? \n",
      "¿ te has dicho que ibas ? \n",
      "¿ te has dicho que estabas cuidando de mí ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_3/spa-eng/segments_eng/heroes_s2_3_eng_aligned_eng0324.csv\n",
      "i 'm <break time=\"120ms\"/> sorry <break time=\"60ms\"/> . are <break time=\"80ms\"/> you breathing ? \n",
      "lo siento . ¿ estás practicando ? \n",
      "lo siento . ¿ estás practicando ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_3/spa-eng/segments_eng/heroes_s2_3_eng_aligned_eng0329.csv\n",
      "with <break time=\"110ms\"/> my help <break time=\"480ms\"/> , of course . \n",
      "con mi ayuda , por supuesto . \n",
      "con mi ayuda , claro . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_3/spa-eng/segments_eng/heroes_s2_3_eng_aligned_eng0375.csv\n",
      "so how would it feel then if i <break time=\"170ms\"/> do this ? \n",
      "¿ y cómo se sentiría si lo hago ? \n",
      "¿ y cómo se sentiría si lo hago ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_4/spa-eng/segments_eng/heroes_s2_4_eng_aligned_eng0083.csv\n",
      "yes , ma 'am . \n",
      "sí , señora . \n",
      "sí , señora . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_4/spa-eng/segments_eng/heroes_s2_4_eng_aligned_eng0089.csv\n",
      "good morning , everybody <break time=\"640ms\"/> . well ? \n",
      "buenos días . \n",
      "buenos días . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_4/spa-eng/segments_eng/heroes_s2_4_eng_aligned_eng0224.csv\n",
      "gabriel <break time=\"3630ms\"/> . gabriel gray . \n",
      "gabriel <break time=\"0000ms\"/> gabriel . gabriel gris . \n",
      "gabriel gabriel . gabriel gris . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_4/spa-eng/segments_eng/heroes_s2_4_eng_aligned_eng0257.csv\n",
      "my situation ? \n",
      "¿ mi situación ? \n",
      "¿ mi situación ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_4/spa-eng/segments_eng/heroes_s2_4_eng_aligned_eng0261.csv\n",
      "i need the money <break time=\"189ms\"/> . and  i mean , i  can 't make hamburgers for the rest of my life \n",
      "necesito el dinero . y quiero decir , no puedo hacer los gofres para el resto . \n",
      "necesito el dinero . y quiero decir , no puedo hacer los postres para el resto ... \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_4/spa-eng/segments_eng/heroes_s2_4_eng_aligned_eng0275.csv\n",
      "what kind of group is it ? \n",
      "¿ qué clase de grupo es ? \n",
      "¿ qué clase de clase ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_4/spa-eng/segments_eng/heroes_s2_4_eng_aligned_eng0364.csv\n",
      "and you haven 't seen him since ? \n",
      "¿ y no le has visto ? \n",
      "¿ y no le has visto desde ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_4/spa-eng/segments_eng/heroes_s2_4_eng_aligned_eng0373.csv\n",
      "please , don 't make me look for him . \n",
      "por favor , no me obligues que me busque . \n",
      "por favor , no me obligues a buscarle . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_4/spa-eng/segments_eng/heroes_s2_4_eng_aligned_eng0380.csv\n",
      "i 'm sure he didn 't suspect a thing . \n",
      "estoy seguro de que no sospecha nada . \n",
      "seguro que no sospecha nada . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_4/spa-eng/segments_eng/heroes_s2_4_eng_aligned_eng0408.csv\n",
      "that 's why you need to find dr <break time=\"60ms\"/> . suresh . \n",
      "por eso necesita que encontrar al dr . suresh . \n",
      "por eso tienes que encontrar al dr . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_4/spa-eng/segments_eng/heroes_s2_4_eng_aligned_eng0412.csv\n",
      "but the police \n",
      "¡ pero a la policía ! \n",
      "¡ pero la policía ! \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_4/spa-eng/segments_eng/heroes_s2_4_eng_aligned_eng0471.csv\n",
      "ok . good . \n",
      "vale . bien . \n",
      "vale . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_5/spa-eng/segments_eng/heroes_s2_5_eng_aligned_eng0014.csv\n",
      "nine . \n",
      "nueve . \n",
      "nueve . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_5/spa-eng/segments_eng/heroes_s2_5_eng_aligned_eng0076.csv\n",
      "do you know where he is now ? \n",
      "¿ sabes dónde está ahora ? \n",
      "¿ sabes dónde está ahora ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_5/spa-eng/segments_eng/heroes_s2_5_eng_aligned_eng0145.csv\n",
      "alright . this is where molly said we 'd find him . \n",
      "tranquila <break time=\"0000ms\"/> . esto es donde molly dijo que le encontraría . \n",
      "tranquila . ahí es donde molly . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_5/spa-eng/segments_eng/heroes_s2_5_eng_aligned_eng0306.csv\n",
      "ok <break time=\"1040ms\"/> . get on with it then . \n",
      "vale <break time=\"0000ms\"/> , entonces . \n",
      "vale , entonces . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_5/spa-eng/segments_eng/heroes_s2_5_eng_aligned_eng0362.csv\n",
      "no  , janice \n",
      "¡ no <break time=\"0000ms\"/> , janice ! \n",
      "¡ no ! ¡ janice ! \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_6/spa-eng/segments_eng/heroes_s2_6_eng_aligned_eng0056.csv\n",
      "others like me ? \n",
      "¿ otros como yo ? \n",
      "¿ otros como yo ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_6/spa-eng/segments_eng/heroes_s2_6_eng_aligned_eng0125.csv\n",
      "you want to be different ? \n",
      "¿ quieres ser distinta ? \n",
      "¿ quieres ser distinta ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_6/spa-eng/segments_eng/heroes_s2_6_eng_aligned_eng0147.csv\n",
      "then  you  know what i 'm  capable of <break time=\"1280ms\"/> . don 't make me  do this . \n",
      "y sabes lo que soy capaz de mi <break time=\"0000ms\"/> , no me obligues hacer esto . \n",
      "y sabes lo que soy capaz de mi , no me obligues hacer esto . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_6/spa-eng/segments_eng/heroes_s2_6_eng_aligned_eng0325.csv\n",
      "i  know . \n",
      "lo sé . \n",
      "lo sé . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_6/spa-eng/segments_eng/heroes_s2_6_eng_aligned_eng0344.csv\n",
      "alright , carp . \n",
      "vale , carpa . \n",
      "vale , carpa . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_6/spa-eng/segments_eng/heroes_s2_6_eng_aligned_eng0368.csv\n",
      "are you ready ? \n",
      "¿ estás listo ? \n",
      "¿ estás listo ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_7/spa-eng/segments_eng/heroes_s2_7_eng_aligned_eng0054.csv\n",
      "mom , did  you make waffles ? \n",
      "mamá , ¿ has hecho gofres ? \n",
      "mamá , ¿ has hecho gofres ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_7/spa-eng/segments_eng/heroes_s2_7_eng_aligned_eng0091.csv\n",
      "virus <break time=\"990ms\"/> ? what virus ? \n",
      "virus virus , ¿ qué virus ? \n",
      "¿ virus virus ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_7/spa-eng/segments_eng/heroes_s2_7_eng_aligned_eng0278.csv\n",
      "look around , pop <break time=\"329ms\"/> . this isn 't my nightmare  it 's yours  . i can walk right out that door . \n",
      "echa <break time=\"0000ms\"/> . esto no es mi pesadilla <break time=\"0000ms\"/> . puedo salir . puedo salir . puedo salir de esa puerta . \n",
      "mira , no es mi pesadilla . puedo salir . puedo salir . puedo salir por ahí . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_7/spa-eng/segments_eng/heroes_s2_7_eng_aligned_eng0287.csv\n",
      "don 't leave me . \n",
      "no me dejes . \n",
      "no me dejes . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_8/spa-eng/segments_eng/heroes_s2_8_eng_aligned_eng0042.csv\n",
      "you <break time=\"120ms\"/> bitch <break time=\"2619ms\"/> let <break time=\"80ms\"/> go of me \n",
      "¡ suelta ! ¡ suelta ! \n",
      "¡ tú me has dejado ! \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_8/spa-eng/segments_eng/heroes_s2_8_eng_aligned_eng0057.csv\n",
      "help  please <break time=\"160ms\"/> , help \n",
      "¡ ayúdeme ! ¡ ayuda ! \n",
      "¡ ayúdeme ! ¡ ayuda ! \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_8/spa-eng/segments_eng/heroes_s2_8_eng_aligned_eng0206.csv\n",
      "no <break time=\"610ms\"/> . they created this facility to help us . \n",
      "no <break time=\"0000ms\"/> . se han creado este lugar para ayudarnos . \n",
      "no . se ha creado este sitio para ayudarnos . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_8/spa-eng/segments_eng/heroes_s2_8_eng_aligned_eng0237.csv\n",
      "you 're  not <break time=\"360ms\"/> real . \n",
      "no eres real real . \n",
      "no eres real . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_8/spa-eng/segments_eng/heroes_s2_8_eng_aligned_eng0266.csv\n",
      "nathan <break time=\"650ms\"/> . how ? \n",
      "nathan . ¿ cómo ? \n",
      "nathan . ¿ cómo ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_8/spa-eng/segments_eng/heroes_s2_8_eng_aligned_eng0291.csv\n",
      "it 's  for the <break time=\"260ms\"/> best , maya . \n",
      "es por lo mejor <break time=\"0000ms\"/> , maya . \n",
      "es por lo mejor , maya . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_8/spa-eng/segments_eng/heroes_s2_8_eng_aligned_eng0316.csv\n",
      "adam , look , look . \n",
      "adam , mira . \n",
      "adam , mira . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_9/spa-eng/segments_eng/heroes_s2_9_eng_aligned_eng0061.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how we gonna do this ? \n",
      "¿ cómo vamos a hacer esto ? \n",
      "¿ cómo pasaremos esto ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_9/spa-eng/segments_eng/heroes_s2_9_eng_aligned_eng0151.csv\n",
      "he 's adorable . \n",
      "es encantador . \n",
      "es encantador . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_9/spa-eng/segments_eng/heroes_s2_9_eng_aligned_eng0182.csv\n",
      "claire butler <break time=\"550ms\"/> , bring  it on <break time=\"290ms\"/> in \n",
      "¡ claire butler , venga ! \n",
      "¡ claire butler ! ¡ venga ! \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_9/spa-eng/segments_eng/heroes_s2_9_eng_aligned_eng0345.csv\n",
      "those <break time=\"330ms\"/> things are awesome . \n",
      "esas cosas son increíbles . \n",
      "esas cosas son increíbles . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s2_9/spa-eng/segments_eng/heroes_s2_9_eng_aligned_eng0353.csv\n",
      "please , don 't do this . \n",
      "por favor , no lo hagas . \n",
      "por favor , no lo haga . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_1/spa-eng/segments_eng/heroes_s3_1_eng_aligned_eng0001.csv\n",
      "come on , claire <break time=\"1150ms\"/> . it 's me . \n",
      "venga , claire <break time=\"0000ms\"/> . soy yo . \n",
      "venga , claire . soy yo . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_1/spa-eng/segments_eng/heroes_s3_1_eng_aligned_eng0060.csv\n",
      "harder than i had wished for . \n",
      "más <break time=\"0000ms\"/> fuerte de lo que quise . \n",
      "más fuerte de lo que quise . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_1/spa-eng/segments_eng/heroes_s3_1_eng_aligned_eng0070.csv\n",
      "i don 't understand . \n",
      "no lo entiendo . \n",
      "no lo entiendo . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_1/spa-eng/segments_eng/heroes_s3_1_eng_aligned_eng0075.csv\n",
      "but you  haven 't even tried \n",
      "¡ pero no has intentado ! \n",
      "¡ pero no has intentado ! \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_1/spa-eng/segments_eng/heroes_s3_1_eng_aligned_eng0078.csv\n",
      "i 'm sorry <break time=\"1440ms\"/> . i should go now . \n",
      "lo siento <break time=\"0000ms\"/> . debí . \n",
      "lo siento . tengo que colgar . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_1/spa-eng/segments_eng/heroes_s3_1_eng_aligned_eng0136.csv\n",
      "we fight our own <break time=\"200ms\"/> personal battles <break time=\"1100ms\"/> but we  know  we 're not alone . \n",
      "peleamos nuestros propios , pero <break time=\"0000ms\"/> sabemos que no estamos solos . \n",
      "luchamos a nuestras personal personales , pero sabemos que no estamos solos . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_1/spa-eng/segments_eng/heroes_s3_1_eng_aligned_eng0152.csv\n",
      "i don 't understand . what have you found ? \n",
      "no lo entiendo <break time=\"0000ms\"/> . ¿ qué has encontrado ? \n",
      "no lo entiendo . ¿ qué has encontrado ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_10/spa-eng/segments_eng/heroes_s3_10_eng_aligned_eng0114.csv\n",
      "please  , just help me  find hiro <break time=\"60ms\"/> . come on . \n",
      "por favor , ayúdame a buscar a buscar . \n",
      "ayúdeme , ayúdeme a hiro . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_10/spa-eng/segments_eng/heroes_s3_10_eng_aligned_eng0134.csv\n",
      "i can 't  help him , i can 't understand him . \n",
      "no puedo ayudarle , no puedo entenderlo . \n",
      "no puedo ayudarle , no puedo entenderlo . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_10/spa-eng/segments_eng/heroes_s3_10_eng_aligned_eng0144.csv\n",
      "you paused . \n",
      "te has dado . \n",
      "te has despertado . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_10/spa-eng/segments_eng/heroes_s3_10_eng_aligned_eng0231.csv\n",
      "i don 't know <break time=\"140ms\"/> . i don 't know  , but i gotta find out . \n",
      "no lo sé <break time=\"0000ms\"/> . no lo sé <break time=\"0000ms\"/> , pero tengo que averiguarlo . \n",
      "no lo sé . no lo sé , pero tengo que averiguarlo . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_10/spa-eng/segments_eng/heroes_s3_10_eng_aligned_eng0239.csv\n",
      "holy crap , it worked . this is it  , this is daphne 's <break time=\"400ms\"/> house . \n",
      "¡ <break time=\"0000ms\"/> basura <break time=\"0000ms\"/> ! ¡ qué <break time=\"0000ms\"/> es <break time=\"0000ms\"/> la casa de daphne ! \n",
      "¡ basura ! ¡ es la casa de daphne ! \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_10/spa-eng/segments_eng/heroes_s3_10_eng_aligned_eng0273.csv\n",
      "i said  let me in . \n",
      "he dicho que me deje . \n",
      "he dicho que me deje . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_10/spa-eng/segments_eng/heroes_s3_10_eng_aligned_eng0278.csv\n",
      "his also . \n",
      "su también . \n",
      "su también . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_10/spa-eng/segments_eng/heroes_s3_10_eng_aligned_eng0290.csv\n",
      "yeah , i 'll <break time=\"220ms\"/> go <break time=\"120ms\"/> get em . \n",
      "sí <break time=\"0000ms\"/> , voy a por la tía . \n",
      "sí , voy a por tía . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_10/spa-eng/segments_eng/heroes_s3_10_eng_aligned_eng0305.csv\n",
      "excuse me ? \n",
      "¿ qué ? ¿ me disculpa ? \n",
      "¿ cómo dices ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_10/spa-eng/segments_eng/heroes_s3_10_eng_aligned_eng0373.csv\n",
      "is he always this quiet ? \n",
      "¿ siempre está tan tranquilo ? \n",
      "¿ siempre está tan tranquilo ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_10/spa-eng/segments_eng/heroes_s3_10_eng_aligned_eng0375.csv\n",
      "listen , i really appreciate your help , but we need to get you back home . \n",
      "oye , agradezco , agradezco mucho que volver a recuperar . pero necesitamos que llevarla a casa . \n",
      "oye , agradezco , agradezco , agradezco , agradezco , agradezco , agradezco , agradezco que te vuelvas a casa de vuelta . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_10/spa-eng/segments_eng/heroes_s3_10_eng_aligned_eng0390.csv\n",
      "you <break time=\"120ms\"/> can 't do this on  your own . \n",
      "no puedes hacer esto . \n",
      "no puedes hacer esto sola . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_10/spa-eng/segments_eng/heroes_s3_10_eng_aligned_eng0394.csv\n",
      "don 't be stupid . \n",
      "no seas estúpida . \n",
      "no seas estúpida . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_10/spa-eng/segments_eng/heroes_s3_10_eng_aligned_eng0400.csv\n",
      "are <break time=\"210ms\"/> you feeling okay ? \n",
      "¿ te encuentras bien ? \n",
      "¿ te encuentras bien ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_10/spa-eng/segments_eng/heroes_s3_10_eng_aligned_eng0428.csv\n",
      "i  have no idea . \n",
      "no tengo ni idea . \n",
      "no tengo ni idea . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_14/spa-eng/segments_eng/heroes_s3_14_eng_aligned_eng0009.csv\n",
      "he was <break time=\"100ms\"/> pinned in there . \n",
      "estaba en serio . \n",
      "estaba en serio . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_16/spa-eng/segments_eng/heroes_s3_16_eng_aligned_eng0083.csv\n",
      "yeah <break time=\"160ms\"/> , i  am . \n",
      "sí <break time=\"0000ms\"/> . \n",
      "sí . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_16/spa-eng/segments_eng/heroes_s3_16_eng_aligned_eng0113.csv\n",
      "just <break time=\"530ms\"/> a <break time=\"100ms\"/> little sad  , that 's all . \n",
      "es un poco <break time=\"0000ms\"/> triste , eso es todo . \n",
      "es un poco triste , eso es todo . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_16/spa-eng/segments_eng/heroes_s3_16_eng_aligned_eng0189.csv\n",
      "look , don 't go home <break time=\"400ms\"/> . don 't use your credit cards or your cell phone . \n",
      "no vuelvas tus apuestas o tu móvil . \n",
      "no vuelvas tus cartas , ni a las buenas o a tu teléfono . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_16/spa-eng/segments_eng/heroes_s3_16_eng_aligned_eng0256.csv\n",
      "please don 't let him hurt me any more  . don 't let him hurt me any more . please \n",
      "por favor , no dejes que me haga daño . ¡ no ! ¡ por favor ! \n",
      "¡ por favor ! ¡ no ! ¡ no te deje daño daño daño ! ¡ por favor ! ¡ por favor ! \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_16/spa-eng/segments_eng/heroes_s3_16_eng_aligned_eng0267.csv\n",
      "you are making a mistake . \n",
      "estás cometiendo un error . \n",
      "estás cometiendo un error . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_2/spa-eng/segments_eng/heroes_s3_2_eng_aligned_eng0013.csv\n",
      "i 'm so  angry <break time=\"480ms\"/> . to think that that monster was <break time=\"80ms\"/> in this house . \n",
      "estoy enfadado que ese monstruo estaba en esta casa . \n",
      "estoy enfadado , para pensar que ese monstruo estaba en esta casa . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_2/spa-eng/segments_eng/heroes_s3_2_eng_aligned_eng0024.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no <break time=\"570ms\"/> , i heal , but i always feel everything . \n",
      "no <break time=\"0000ms\"/> , me <break time=\"0000ms\"/> curo , pero <break time=\"0000ms\"/> siempre siento . \n",
      "no , curo , pero siempre me siento todo . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_2/spa-eng/segments_eng/heroes_s3_2_eng_aligned_eng0094.csv\n",
      "miss strauss ? \n",
      "¿ la srta . strauss . \n",
      "¿ la srta . strauss ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_2/spa-eng/segments_eng/heroes_s3_2_eng_aligned_eng0124.csv\n",
      "you could teach me <break time=\"700ms\"/> . you learned how to use your power and you fought him . \n",
      "podrías enseñarme . lo has hecho como usar tu poder y tú le has hecho . \n",
      "podrías enseñarme . has aprendido tu poder y lo has hecho . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_2/spa-eng/segments_eng/heroes_s3_2_eng_aligned_eng0127.csv\n",
      "i can 't <break time=\"230ms\"/> . not me . not now . \n",
      "no puedo . yo no puedo . \n",
      "no puedo . yo no puedo . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_2/spa-eng/segments_eng/heroes_s3_2_eng_aligned_eng0129.csv\n",
      "i  need someone to help me . \n",
      "necesito a alguien . \n",
      "necesito a alguien . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_2/spa-eng/segments_eng/heroes_s3_2_eng_aligned_eng0130.csv\n",
      "it <break time=\"60ms\"/> can 't be me , claire . \n",
      "no puede ser yo <break time=\"0000ms\"/> . \n",
      "no puede ser yo , claire . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_2/spa-eng/segments_eng/heroes_s3_2_eng_aligned_eng0178.csv\n",
      "you know , you are so sure that i 'm going to disappoint you , but <break time=\"130ms\"/> when i prove you wrong \n",
      "verás seguro de que te voy a confiar , pero cuando te lo he hecho mal . \n",
      "¡ seguro ! estás seguro que te voy a hundir , pero cuando te digo mal ... \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_2/spa-eng/segments_eng/heroes_s3_2_eng_aligned_eng0210.csv\n",
      "i need your forgiveness . \n",
      "necesito tu perdón . \n",
      "necesito tu perdón . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_2/spa-eng/segments_eng/heroes_s3_2_eng_aligned_eng0256.csv\n",
      "you  are not faster than me , nemesis . \n",
      "no eres más rápido que yo , némesis . \n",
      "no eres más rápido que yo , némesis . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_2/spa-eng/segments_eng/heroes_s3_2_eng_aligned_eng0351.csv\n",
      "my <break time=\"200ms\"/> sons have been such a disappointment . \n",
      "mis hijos han sido muy mal . \n",
      "mis hijos han sido muy grandes . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_6/spa-eng/segments_eng/heroes_s3_6_eng_aligned_eng0012.csv\n",
      "the  future has  changed . \n",
      "el futuro ha cambiado . \n",
      "el futuro ha cambiado . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_6/spa-eng/segments_eng/heroes_s3_6_eng_aligned_eng0082.csv\n",
      "ah <break time=\"390ms\"/> i 'm not afraid . \n",
      "no tengo miedo . \n",
      "no tengo miedo . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_6/spa-eng/segments_eng/heroes_s3_6_eng_aligned_eng0089.csv\n",
      "that would be a mistake , my dear . \n",
      "eso sería un error , mi querido . \n",
      "eso sería un error , mi querida . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_6/spa-eng/segments_eng/heroes_s3_6_eng_aligned_eng0098.csv\n",
      "look there 's your next assignment . \n",
      "mira que esta próxima misión . \n",
      "mira , tu próxima misión . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_6/spa-eng/segments_eng/heroes_s3_6_eng_aligned_eng0109.csv\n",
      "she 's not niki . \n",
      "no es niki . \n",
      "no es niki . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_6/spa-eng/segments_eng/heroes_s3_6_eng_aligned_eng0119.csv\n",
      "i don 't know , i was just a baby . \n",
      "no lo sé <break time=\"0000ms\"/> , sólo era un bebé . \n",
      "no lo sé , sólo era un bebé . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_6/spa-eng/segments_eng/heroes_s3_6_eng_aligned_eng0132.csv\n",
      "they know  how you 've been waiting your whole life just <break time=\"780ms\"/> to be somebody . \n",
      "saben como has estado esperando <break time=\"0000ms\"/> a alguien . \n",
      "ya sabes cómo has estado esperando para ser una vida . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_6/spa-eng/segments_eng/heroes_s3_6_eng_aligned_eng0134.csv\n",
      "no , i am . i <break time=\"620ms\"/> just got a lot of appointments today . \n",
      "no <break time=\"0000ms\"/> , soy <break time=\"0000ms\"/> yo tengo muchas . \n",
      "no , estoy . tengo muchas . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_6/spa-eng/segments_eng/heroes_s3_6_eng_aligned_eng0149.csv\n",
      "look  , i have a bunch of stuff to do today , but <break time=\"1060ms\"/> can you  wait here ? \n",
      "oye , tengo un montón , pero <break time=\"0000ms\"/> puedes esperar aquí . ¿ puedes esperar ? \n",
      "oye , tengo un montón de cosas que hacer hoy , pero ¿ puedes esperar aquí ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_6/spa-eng/segments_eng/heroes_s3_6_eng_aligned_eng0179.csv\n",
      "i need your <break time=\"330ms\"/> help . \n",
      "necesito tu ayuda . \n",
      "necesito tu ayuda . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_6/spa-eng/segments_eng/heroes_s3_6_eng_aligned_eng0189.csv\n",
      "this is not about you and <break time=\"260ms\"/> me <break time=\"780ms\"/> . i woke you because your mother 's in trouble . \n",
      "esto no es por <break time=\"0000ms\"/> ti <break time=\"0000ms\"/> y yo . te desperté porque tu madre está en peligro . \n",
      "no es de ti y yo te desperté porque tu madre está en peligro . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_6/spa-eng/segments_eng/heroes_s3_6_eng_aligned_eng0316.csv\n",
      "i <break time=\"520ms\"/> have to go back . i don 't have a choice . \n",
      "tengo que volver . no tengo alternativa . \n",
      "tengo que volver . no tengo alternativa . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_8/spa-eng/segments_eng/heroes_s3_8_eng_aligned_eng0176.csv\n",
      "that 's my favorite kind . \n",
      "es mi favorita . \n",
      "es mi favorita favorita . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_8/spa-eng/segments_eng/heroes_s3_8_eng_aligned_eng0260.csv\n",
      "flint . flint , you got to  understand something <break time=\"100ms\"/> . you can 't ever trust the company . \n",
      "flint flint , debes entender . no puedes confiar en la compañía . \n",
      "flint flint , tienes que entender . no puedes confiar la compañía . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_8/spa-eng/segments_eng/heroes_s3_8_eng_aligned_eng0331.csv\n",
      "oh , my <break time=\"60ms\"/> god . \n",
      "¡ dios santo ! \n",
      "¡ dios santo ! \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_8/spa-eng/segments_eng/heroes_s3_8_eng_aligned_eng0332.csv\n",
      "our son , arthur <break time=\"110ms\"/> . our own son . \n",
      "nuestro hijo , arthur . \n",
      "nuestro hijo , arthur . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_9/spa-eng/segments_eng/heroes_s3_9_eng_aligned_eng0044.csv\n",
      "what ? \n",
      "¿ qué ? \n",
      "¿ qué ? \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_9/spa-eng/segments_eng/heroes_s3_9_eng_aligned_eng0074.csv\n",
      "then you 'll just have to keep looking . \n",
      "entonces tendrá que seguir que seguir . \n",
      "entonces tendrá que seguir buscando . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_9/spa-eng/segments_eng/heroes_s3_9_eng_aligned_eng0251.csv\n",
      "matt <break time=\"1520ms\"/> ? matt , wake up <break time=\"630ms\"/> . matt , wake up . \n",
      "matt , matt , despierta , despierta , despierta , despierta , despierta , despierta , despierta . \n",
      "matt , matt , matt , despierta . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_9/spa-eng/segments_eng/heroes_s3_9_eng_aligned_eng0262.csv\n",
      "she betrayed you <break time=\"190ms\"/> , matt <break time=\"750ms\"/> . like angela betrayed me . \n",
      "te traicionó <break time=\"0000ms\"/> , matt <break time=\"0000ms\"/> . como ángela , como ángela me ha traicionado . \n",
      "te ha traicionado , matt . como ángela me ha traicionado . \n",
      "----------------\n",
      "/Users/alp/Movies/heroes/corpus/heroes_s3_9/spa-eng/segments_eng/heroes_s3_9_eng_aligned_eng0272.csv\n",
      "we were once like that , arthur . \n",
      "nos hemos hecho <break time=\"0000ms\"/> así , arthur . \n",
      "íbamos así , arthur . \n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "#Text+prosody -> text+prosody on audio data visualization\n",
    "print_every = 1\n",
    "print_count = 0\n",
    "print_strings_for_prosody_evaluation = []\n",
    "for in_sentence_tokens, in_prosody_tokens, out_sentence_tokens, out_prosody_tokens, in_csv, out_csv in gen:\n",
    "    print(in_csv)\n",
    "#     print(out_csv)\n",
    "    \n",
    "    in_string = print_tokens_with_pause(in_sentence_tokens, in_prosody_tokens[:,0], ssml_format=True, min_pause_duration = 0.05)\n",
    "#     gt_string = print_tokens_with_pause(out_sentence_tokens, out_prosody_tokens[:,0], ssml_format=True, min_pause_duration = 0.05)\n",
    "    \n",
    "    translation_tokens, pauseflag_tokens, attentions = evaluate_audio(in_sentence_tokens, in_prosody_tokens, input_lang, output_lang, prosodic_encoder, prosodic_decoder, max_seq_length, audio_encode_only=AUDIO_ENCODE_ONLY)\n",
    "    prosody_translation_string = print_tokens_with_pause(translation_tokens, pauseflags=pauseflag_tokens, ssml_format=True)\n",
    "\n",
    "    translation_tokens, _ = evaluate_text(in_sentence_tokens, input_lang, output_lang, text_encoder, text_decoder, max_seq_length)\n",
    "    text_translation_string = print_tokens_with_pause(translation_tokens)\n",
    "\n",
    "#     print_string = '%s\\t%s\\t%s'%(in_string, gt_string, prosody_translation_string)\n",
    "#     print_strings_for_prosody_evaluation.append(print_string)\n",
    "    \n",
    "    print_count += 1\n",
    "    if print_every > 0 and  print_count % print_every == 0:\n",
    "#         print(\"IN\")\n",
    "        print(in_string)\n",
    "#         print(\"GT\")\n",
    "#         print(gt_string)\n",
    "#         print(\"OUT PROSODY\")\n",
    "        print(prosody_translation_string)\n",
    "#         print(\"OUT TEXT\")\n",
    "        print(text_translation_string)\n",
    "        print(\"----------------\")\n",
    "        \n",
    "#         inp = input(\"...\")\n",
    "#         if inp == 'q':\n",
    "#             break\n",
    "#         print(\"======================================================================\")\n",
    "    \n",
    "# with open('prosody_eval.txt', 'w') as f:\n",
    "#     for eval_str in print_strings_for_prosody_evaluation:\n",
    "#         f.write(eval_str+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text -> text on text data\n",
    "def text_set_translation_generator(stop_at = -1, report=False):\n",
    "    for in_sentence_tokens, out_sentence_tokens in text_data_generator(TEXT_TEST_DATA_PATH, input_lang, output_lang, stop_at):\n",
    "        translation_tokens, _ = evaluate_text(in_sentence_tokens, input_lang, output_lang, text_encoder, text_decoder, max_seq_length)\n",
    "        if report:\n",
    "            print(\"> %s\"%(readable_from_tokens(in_sentence_tokens)))\n",
    "            print(\"= %s\"%(readable_from_tokens(out_sentence_tokens)))\n",
    "            print(\"< %s\"%readable_from_tokens(translation_tokens[:-1]))\n",
    "            print(\"---\")\n",
    "        \n",
    "        yield [out_sentence_tokens], translation_tokens[:-1]\n",
    "        \n",
    "testing_set_bleu, sentence_count = compute_bleu(text_set_translation_generator(stop_at=10, report=True), max_order=4, smooth=False)\n",
    "\n",
    "print(\"Evaluated %i samples.\"%sentence_count)\n",
    "print(\"BLEU: \", testing_set_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated 542 samples.\n",
      "BLEU:  0.20721749327822875\n"
     ]
    }
   ],
   "source": [
    "#Text -> text on audio data\n",
    "gold_sentence_tokens = []\n",
    "predicted_sentence_tokens = []\n",
    "in_sentences = []\n",
    "def audio_set_text_translation_generator(evaluation_set, stop_at = -1, report=False, model='text'):\n",
    "    for in_sentence_tokens, in_prosody_tokens , out_sentence_tokens, out_prosody_tokens, in_csv, out_csv in audio_data_generator(evaluation_set, input_lang, output_lang, n_prosody_params, input_prosody_params, output_prosody_params, stop_at=stop_at):\n",
    "        if model == 'text':\n",
    "            translation_tokens, _ = evaluate_text(in_sentence_tokens, input_lang, output_lang, text_encoder, text_decoder, max_seq_length)\n",
    "        elif model == 'audio':\n",
    "            translation_tokens, _, _ = evaluate_audio(in_sentence_tokens, in_prosody_tokens, input_lang, output_lang, prosodic_encoder, prosodic_decoder, max_seq_length, AUDIO_ENCODE_ONLY)\n",
    "        if report:\n",
    "            print(\"> %s\"%(readable_from_tokens(in_sentence_tokens)))\n",
    "            print(\"= %s\"%(readable_from_tokens(out_sentence_tokens)))\n",
    "            print(\"< %s\"%readable_from_tokens(translation_tokens[:-1]))\n",
    "            print(\"---\")\n",
    "            \n",
    "        in_sentences.append(readable_from_tokens(in_sentence_tokens))\n",
    "        gold_sentence_tokens.append(out_sentence_tokens)\n",
    "        predicted_sentence_tokens.append(translation_tokens[:-1])\n",
    "        yield [out_sentence_tokens], translation_tokens[:-1]\n",
    "             \n",
    "#evaluation_set = AUDIO_PUNKPROSED_TEST_NEW_DATA_PATH\n",
    "evaluation_set = AUDIO_TEST_DATA_PATH\n",
    "\n",
    "testing_set_bleu, sentence_count = compute_bleu(\n",
    "    audio_set_text_translation_generator(evaluation_set, report=False, stop_at=-1, model='audio'), \n",
    "    max_order=4, smooth=False)\n",
    "\n",
    "print(\"Evaluated %i samples.\"%sentence_count)\n",
    "print(\"BLEU: \", testing_set_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alp/extSW/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:6: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "/Users/alp/extSW/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:17: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "/Users/alp/extSW/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:6: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n"
     ]
    }
   ],
   "source": [
    "in_sentences = []\n",
    "for in_sentence_tokens, in_prosody_tokens , out_sentence_tokens, out_prosody_tokens, in_csv, out_csv in audio_data_generator(evaluation_set, input_lang, output_lang, n_prosody_params, input_prosody_params, output_prosody_params, stop_at=-1):\n",
    "    in_string = print_tokens_with_pause(in_sentence_tokens, in_prosody_tokens[:,0], ssml_format=False)\n",
    "    in_sentences.append(in_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def bleu_generator(pred_audio, gold):\n",
    "def gen():\n",
    "    yield [pred_audio], gold\n",
    "\n",
    "compute_bleu(gen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN:  holy crap , it worked . this is it [P] , this is daphne 's [P] house . \n",
      "TEXT:  ¡ basura ! mierda , es la casa de daphne . ¡ es la casa de daphne !\n",
      "AUDIO:  ¡ coño ! ¡ santo ! ¡ esto es la casa de daphne !\n",
      "GOLD:  ha funcionado . es aquí . es la casa de daphne .\n",
      "-------------------------------------------------------------\n",
      "IN:  but , for now [P] , you just rest [P] . i 'll be right downstairs . \n",
      "TEXT:  pero ahora , descansa . enseguida . enseguida . enseguida .\n",
      "AUDIO:  pero ahora , por ahora , descansa . enseguida . enseguida enseguida .\n",
      "GOLD:  pero , por ahora , descansa . yo estaré en el salón .\n",
      "-------------------------------------------------------------\n",
      "IN:  that 's claire [P] and that 's hiro , hiding behind the ferns . \n",
      "TEXT:  claire y ese es hiro , ocultando detrás , escondido de las cometas .\n",
      "AUDIO:  esa es claire y ese es hiro , ocultando detrás , detrás de las cometas .\n",
      "GOLD:  esa es claire . y ese es hiro , detrás de los cristales .\n",
      "-------------------------------------------------------------\n",
      "IN:  where is [P] he [P] ? where did they go ? \n",
      "TEXT:  ¿ dónde está ? ¿ adónde han ido ?\n",
      "AUDIO:  ¿ dónde está ? ¿ dónde han ido ?\n",
      "GOLD:  ¿ dónde está ? ¿ dónde se ha metido ?\n",
      "-------------------------------------------------------------\n",
      "IN:  you disarmed 11 men [P] and rescued a [P] beautiful girl . \n",
      "TEXT:  has atacado a los hombres y han secuestrado a una chica preciosa .\n",
      "AUDIO:  has atacado a las hombres y rescatar a una chica preciosa .\n",
      "GOLD:  desarmar a once hombres y rescatar a una damisela .\n",
      "-------------------------------------------------------------\n",
      "IN:  every time you would come home from a trip [P] , i 'd always hug you as tight as i could . \n",
      "TEXT:  cada vez que te ibas a casa de un viaje , siempre te abrazo tanto .\n",
      "AUDIO:  cada vez que vendrías a casa de un viaje , siempre te abrazo tanto .\n",
      "GOLD:  cada vez que volvías de un viaje , te abrazaba con todas mis fuerzas .\n",
      "-------------------------------------------------------------\n",
      "IN:  it must be serious to [P] make [P] such a [P] dangerous [P] journey . \n",
      "TEXT:  debe de ser grave .\n",
      "AUDIO:  debe ser serio para hacer un viaje tan peligroso .\n",
      "GOLD:  debe ser bastante grave como para hacer un viaje así de peligroso .\n",
      "-------------------------------------------------------------\n",
      "IN:  i 'm [P] gonna [P] make things right , pete . \n",
      "TEXT:  voy a hacer , pete .\n",
      "AUDIO:  voy a hacer las cosas , pete .\n",
      "GOLD:  voy a arreglar las cosas , pete .\n",
      "-------------------------------------------------------------\n",
      "IN:  there 's not much at stake here [P] just the fate of the entire human race . \n",
      "TEXT:  no hay mucho en juego aquí . el destino de la raza humana .\n",
      "AUDIO:  no hay mucho en juego , sólo el destino de la raza humana .\n",
      "GOLD:  bueno , no hay mucho en juego , sólo el destino de la raza humana .\n",
      "-------------------------------------------------------------\n",
      "IN:  if you visit me one more time , detective [P] parkman \n",
      "TEXT:  si me visitas uno más , agente parkman ...\n",
      "AUDIO:  si me visitas una vez más , detective parkman ...\n",
      "GOLD:  como vuelva a visitarme , detective parkman ...\n",
      "-------------------------------------------------------------\n",
      "IN:  then how [P] ? pinehearst has a way [P] , pete . \n",
      "TEXT:  ¿ cómo ? ¿ cómo ? ¿ cómo ? ¿ cómo ?\n",
      "AUDIO:  ¿ y cómo ? ¿ cómo ?\n",
      "GOLD:  ¿ y cómo ? pinehearst tiene una solución , pete .\n",
      "-------------------------------------------------------------\n",
      "IN:  adam [P] was dangerous [P] . so we locked him up [P] and [P] threw away the key . \n",
      "TEXT:  adam era peligroso . le encerramos y se ha encerrado y se ha dejado y nos han quitado .\n",
      "AUDIO:  adam era peligroso . lo encerramos y tiramos la llave .\n",
      "GOLD:  adam era peligroso , así que le encerramos y tiramos la llave .\n",
      "-------------------------------------------------------------\n",
      "IN:  i 'm afraid the poison [P] caused irreversible damage to the peripheral nervous system [P] . the paralysis will likely be permanent . \n",
      "TEXT:  me temo que el daño causado causado al sistema del sistema nervioso .\n",
      "AUDIO:  me temo que el veneno le causado causado daño al sistema del sistema nervioso .\n",
      "GOLD:  me temo que el veneno ha causado un daño ... irreparable al sistema nervioso periférico . es probable que la parálisis sea permanente .\n",
      "-------------------------------------------------------------\n",
      "IN:  these ordinary people [P] , like you [P] , like me [P] , are [P] capable [P] of extraordinary things . \n",
      "TEXT:  a mí personas normales como tú , como yo , capaces de cosas extraordinaria .\n",
      "AUDIO:  a mí personas normales como tú , son capaces de cosas extraordinaria .\n",
      "GOLD:  esas personas corrientes , como ustedes , como yo , son capaces de cosas extraordinarias .\n",
      "-------------------------------------------------------------\n",
      "IN:  no [P] , because today [P] is the [P] day \n",
      "TEXT:  ¡ no ! porque hoy no ! porque hoy no !\n",
      "AUDIO:  no , porque hoy es el día .\n",
      "GOLD:  no , porque hoy es el día ...\n",
      "-------------------------------------------------------------\n",
      "IN:  the day that he died [P] , isaac mendez bequeathed his sketchbook to a humble bike messenger [P] . you find that messenger and you find your story [P] . it 's got nothing to do with dad . i 'm going [P] to [P] pinehearst . \n",
      "TEXT:  el día que ha muerto , isaac méndez su padre y le ha convencido sus hazañas y tu guarda , no tiene nada que ver con papá , papá y tú le cuentas .\n",
      "AUDIO:  el día que murió , isaac méndez le ha contado sus hazañas y tu historia no tiene nada que ver con papá , ¿ verdad ?\n",
      "GOLD:  pero no es la última historia . el día en que murió , isaac méndez entregó su cuaderno de bocetos a un humilde mensajero . no tiene que ver con papá .\n",
      "-------------------------------------------------------------\n",
      "IN:  you [P] are [P] in a facility designed to help people just like you . \n",
      "TEXT:  estás en un centro que ayudar a la gente .\n",
      "AUDIO:  estás en un centro que ayudar tú a personas a personas como tú .\n",
      "GOLD:  estás en un centro diseñado para ayudar a personas como tú .\n",
      "-------------------------------------------------------------\n",
      "IN:  your brother tried to kill me [P] . he took sylar 's ability and now he 's suffering the consequences . \n",
      "TEXT:  tu hermano intentó matarme . y ahora me ha dejado las consecuencias .\n",
      "AUDIO:  tu hermano ha intentado a mi y ahora que sufrir las consecuencias y ahora ha causado las consecuencias .\n",
      "GOLD:  tu hermano ha intentado matarme . ha absorbido el poder de salar y sufre las consecuencias .\n",
      "-------------------------------------------------------------\n",
      "IN:  come on , claire [P] . it 's me . \n",
      "TEXT:  vamos , claire , soy yo .\n",
      "AUDIO:  venga , claire . soy yo .\n",
      "GOLD:  vamos , claire . soy yo .\n",
      "-------------------------------------------------------------\n",
      "IN:  i [P] have no idea . \n",
      "TEXT:  no tengo idea .\n",
      "AUDIO:  no tengo ni idea .\n",
      "GOLD:  no tengo ni idea .\n",
      "-------------------------------------------------------------\n",
      "IN:  neither am i [P] . that 's why i 'm [P] going to philadelphia \n",
      "TEXT:  ni yo soy yo . ¡ por eso me voy a filadelfia !\n",
      "AUDIO:  ni yo tampoco soy por eso que voy a filadelfia .\n",
      "GOLD:  yo tampoco . por eso voy a filadelfia .\n",
      "-------------------------------------------------------------\n",
      "IN:  from [P] the day we [P] were [P] born . \n",
      "TEXT:  desde el día de los que nacieron .\n",
      "AUDIO:  desde el día que hemos nacido .\n",
      "GOLD:  desde el día que nacimos .\n",
      "-------------------------------------------------------------\n",
      "IN:  please don 't let him hurt me any more [P] . don 't let him hurt me any more . please \n",
      "TEXT:  ¡ por favor ! ¡ por favor ! ¡ no le dejes daño ! ¡ por favor ! ¡ por favor ! ¡ por favor ! ¡ por favor ! ¡ por favor ! ¡ por favor !\n",
      "AUDIO:  ¡ por favor ! ¡ no dejes daño daño ! ¡ por favor ! ¡ por favor !\n",
      "GOLD:  por favor , que no me haga más daño . no deje que me haga más daño . ¡ por favor !\n",
      "-------------------------------------------------------------\n",
      "IN:  i [P] have to go back . i don 't have a choice . \n",
      "TEXT:  tengo que volver . no tengo alternativa alternativa .\n",
      "AUDIO:  tengo que irme . no tengo alternativa .\n",
      "GOLD:  debo volver , no tengo alternativa .\n",
      "-------------------------------------------------------------\n",
      "IN:  the moon controls [P] the ocean 's waves , the sun , our internal timing , but [P] something [P] is happening to me . \n",
      "TEXT:  la luna controla los rayos , el sol , nuestro cambio , nuestro cambio , el sol , el sol , el sol , el sol , el sol , el sol , el sol , el sol ,\n",
      "AUDIO:  la luna controla el rayo , el sol , nuestro mente , pero algo me va a mí .\n",
      "GOLD:  la luna controla las olas del mar , las olas del mar , el sol , nuestro reloj interno ... pero , algo me está afectando .\n",
      "-------------------------------------------------------------\n",
      "IN:  we can save the world [P] together . \n",
      "TEXT:  podemos salvar el mundo juntos .\n",
      "AUDIO:  podemos salvar al mundo .\n",
      "GOLD:  podemos salvar al mundo , juntos .\n",
      "-------------------------------------------------------------\n",
      "IN:  when the moon passes between the sun and the earth [P] , a [P] strange fascination takes root in the [P] heart , and suddenly [P] anything is possible . \n",
      "TEXT:  cuando la luna se acerca entre el sol y la tierra , una fascinación fascinación , una fascinación fascinación , una fascinación fascinación , una fascinación fascinación , una fascinación fascinación , una fascinación fascinación , una fascinación fascinación\n",
      "AUDIO:  cuando la luna se acerca entre el sol y la tierra , una fascinación fascinación se ha desarrollado el opio del corazón , y de repente .\n",
      "GOLD:  cuando la luna pasa entre el sol y la tierra , una extraña fascinación se apodera de nuestro corazón ... y , de repente , todo es posible .\n",
      "-------------------------------------------------------------\n",
      "IN:  i 'm not choosing sides [P] . this is about claire 's blood [P] curing niki . \n",
      "TEXT:  no me gustan a los secundarios .\n",
      "AUDIO:  no me gustan a los demás , es la sangre de claire de claire .\n",
      "GOLD:  no escojo ningún bando , se trata de que la sangre de claire cure a niki .\n",
      "-------------------------------------------------------------\n",
      "IN:  i 'm so [P] angry [P] . to think that that monster was [P] in this house . \n",
      "TEXT:  estoy enfadado , creo que ese monstruo estaba en esta casa .\n",
      "AUDIO:  estoy tan enfadado , como pensar que ese monstruo en esta casa .\n",
      "GOLD:  ¡ qué rabia me da ! pensar que ese monstruo ha estado en esta casa .\n",
      "-------------------------------------------------------------\n",
      "IN:  alejandro [P] , we [P] should put our faith in him . \n",
      "TEXT:  alejandro , debemos poner poner nuestra fe .\n",
      "AUDIO:  alejandro , debemos poner nuestra fe .\n",
      "GOLD:  alejandro , debemos poner nuestra fe en él .\n",
      "-------------------------------------------------------------\n",
      "IN:  i knew a woman [P] at the company [P] . victoria pratt . \n",
      "TEXT:  conocí a una mujer de la compañía . victoria pratt . pratt pratt . pratt .\n",
      "AUDIO:  conocí a una mujer en la compañía . victoria pratt .\n",
      "GOLD:  conocí a una mujer en la compañía , victoria pratt .\n",
      "-------------------------------------------------------------\n",
      "IN:  i guess the next step for us [P] is [P] phasing out the extra parts . \n",
      "TEXT:  el siguiente paso a las que nos las arreglamos polos .\n",
      "AUDIO:  supongo que el siguiente paso suelto sin las unidades .\n",
      "GOLD:  supongo que el siguiente paso ... será descartar las partes que nos sobran .\n",
      "-------------------------------------------------------------\n",
      "IN:  and circumstances [P] have obviously changed and we won 't be needing your services any more . \n",
      "TEXT:  y las circunstancias , pero ya ha cambiado y no nos volveremos más .\n",
      "AUDIO:  y las circunstancias han cambiado y no nos volveremos más .\n",
      "GOLD:  evidentemente , las circunstancias han cambiado ... y ya no necesitaremos tus servicios aquí .\n",
      "-------------------------------------------------------------\n",
      "IN:  you found a way to suppress it [P] . how ? \n",
      "TEXT:  has encontrado cómo .\n",
      "AUDIO:  has encontrado una forma de evitarlo . ¿ cómo ?\n",
      "GOLD:  habías conseguido anularlo . ¿ cómo ?\n",
      "-------------------------------------------------------------\n",
      "IN:  i know it hasn 't been easy [P] losing me as a brother and a friend , but [P] you need to know [P] , what i 'm doing is hugely important for this country [P] , for the world . \n",
      "TEXT:  sé que no me ha sido fácil sacarme como un hermano y un amigo , pero ... pero tienes que saber saber es muy importante para este país , para el mundo .\n",
      "AUDIO:  sé que no me ha sido fácil perder como un hermano y un amigo , pero tienes que saber es muy importante para este país , para el mundo .\n",
      "GOLD:  que lo que hago es importante para el país , para el mundo .\n",
      "-------------------------------------------------------------\n",
      "IN:  i can 't [P] help him , i can 't understand him . \n",
      "TEXT:  no puedo ayudarle , no puedo entenderlo .\n",
      "AUDIO:  no puedo ayudarle , no le entiendo .\n",
      "GOLD:  no puedo ayudarle , no le entiendo .\n",
      "-------------------------------------------------------------\n",
      "IN:  we were old [P] friends [P] . sometimes simple conversations can be misconstrued . \n",
      "TEXT:  éramos amigos .\n",
      "AUDIO:  éramos amigos . a veces normales normales difíciles .\n",
      "GOLD:  eramos amigos . a veces , una simple conversación se malinterpreta .\n",
      "-------------------------------------------------------------\n",
      "IN:  my mother is sitting in jail [P] for [P] kaito 's murder . \n",
      "TEXT:  mi madre está sentado en la cárcel para kaito .\n",
      "AUDIO:  mi madre está sentado en la cárcel por el asesinato .\n",
      "GOLD:  mi madre está en la cárcel por el asesinato de kaito .\n",
      "-------------------------------------------------------------\n",
      "IN:  you [P] ? how are you gonna [P] help [P] ? you gonna make me some more eggs ? \n",
      "TEXT:  ¿ cómo vas a ayudar más ?\n",
      "AUDIO:  ¿ cómo vas a ayudar ? ¿ me vas a hacerme unos huevos ?\n",
      "GOLD:  ¿ tú ? ¿ cómo me vas a ayudar ? ¿ preparándome mas huevos ?\n",
      "-------------------------------------------------------------\n",
      "IN:  yes [P] , but [P] if you like lizards , that 's awesome and have fun . \n",
      "TEXT:  sí , pero si te gustan las criaturas , eso es increíble y divertido .\n",
      "AUDIO:  sí , pero si te gustan las criaturas , eso es divertido .\n",
      "GOLD:  sí , pero si te gustan los lagartos , pásatelo bien .\n",
      "-------------------------------------------------------------\n",
      "IN:  the most common motives are [P] money and sex . \n",
      "TEXT:  los más de los motivos son el dinero y sexo .\n",
      "AUDIO:  los más motivos son dinero y sexo .\n",
      "GOLD:  los motivos más comunes son dinero y sexo .\n",
      "-------------------------------------------------------------\n",
      "IN:  we fight our own [P] personal battles [P] but we [P] know [P] we 're not alone . \n",
      "TEXT:  peleamos nuestros propios personales , pero sabemos que sabemos que no estamos solos .\n",
      "AUDIO:  luchamos a nuestras , pero sabemos que no estamos solos .\n",
      "GOLD:  libramos nuestras batallas personales , pero no estamos solos .\n",
      "-------------------------------------------------------------\n",
      "IN:  there are many ways [P] to deﬁne our fragile existence [P] . many ways to give it meaning . \n",
      "TEXT:  hay muchas opciones que se frágil .\n",
      "AUDIO:  hay muchas formas de nuestra vida frágil .\n",
      "GOLD:  hay muchas formas de deﬁnir nuestra frágil existencia , muchas formas de darle signiﬁcado .\n",
      "-------------------------------------------------------------\n",
      "IN:  if he 's so dangerous , sweetheart [P] , why 'd they send a little girl like you in all alone ? \n",
      "TEXT:  si tan peligroso , cariño , ¿ por qué le han enviado a una niña como tú ?\n",
      "AUDIO:  si es tan peligroso , cariño , ¿ por qué le enviado a una niña como tú ?\n",
      "GOLD:  si es tan peligroso , ¿ por qué han enviado a una chiquilla como tú ?\n",
      "-------------------------------------------------------------\n",
      "IN:  i 've been trying to tell you [P] . the guy in the glasses is my father . \n",
      "TEXT:  he intentado a decirte . el tío de las gafas es mi padre .\n",
      "AUDIO:  intentaba decirte . el tío de las gafas es mi padre .\n",
      "GOLD:  es lo que intentaba decirte ... el de las gafas es mi padre .\n",
      "-------------------------------------------------------------\n",
      "IN:  well , we [P] couldn 't be angels [P] if everyone [P] knew [P] , now [P] , could we ? \n",
      "TEXT:  no podríamos ser ángeles si el mundo lo supieran , ¿ verdad ?\n",
      "AUDIO:  no podríamos ser ángeles si todos lo supieran , ¿ verdad ?\n",
      "GOLD:  no podríamos ser ángeles ... si todos lo supieran , ¿ no crees ?\n",
      "-------------------------------------------------------------\n",
      "IN:  this is not about you and [P] me [P] . i woke you because your mother 's in trouble . \n",
      "TEXT:  no es sobre ti y yo . he despertado porque tu madre está en peligro .\n",
      "AUDIO:  no es de ti y yo . te desperté porque tu madre está en peligro .\n",
      "GOLD:  esto no va con nosotros . te he llamado porque tu madre está en peligro .\n",
      "-------------------------------------------------------------\n",
      "IN:  she betrayed you [P] , matt [P] . like angela betrayed me . \n",
      "TEXT:  te traicionó , matt , matt . como me angela me ha traicionado .\n",
      "AUDIO:  te ha traicionado , matt . como ángela me ha traicionado .\n",
      "GOLD:  te ha traicionado , matt , igual que angela me traicionó a mí .\n",
      "-------------------------------------------------------------\n",
      "IN:  they know how [P] you struggled as a cop in la [P] to protect and serve , but that wasn 't enough for [P] you [P] , was [P] it ? \n",
      "TEXT:  saben como has trabajado como un poli de ángeles y lo que te ha hecho , pero no es suficiente para ti , ¿ verdad ?\n",
      "AUDIO:  saben como has trabajado como un poli en el ángeles , pero no es suficiente para ti , pero no lo suficiente , ¿ verdad ?\n",
      "GOLD:  saben como luchaste para ser poli en los ángeles , para servir a los demás , pero que eso no te bastaba , ¿ verdad ?\n",
      "-------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for in_sent, pred_text, pred_audio, gold in zip(in_sentences, predicted_sentence_tokens_textmodel, predicted_sentence_tokens_audiomodel, gold_sentence_tokens):\n",
    "    def gen2():\n",
    "        yield [pred_text], gold\n",
    "    def gen1():\n",
    "        yield [pred_audio], gold\n",
    "        \n",
    "    bleu_text = compute_bleu(gen2())[0]\n",
    "    bleu_audio = compute_bleu(gen1())[0]\n",
    "    \n",
    "    if not pred_text == pred_audio and '[P]' in in_sent and bleu_text < bleu_audio:\n",
    "        print('IN: ', in_sent)\n",
    "        print('TEXT: ', ' '.join(pred_text))\n",
    "        print('AUDIO: ', ' '.join(pred_audio))\n",
    "        print('GOLD: ', ' '.join(gold))\n",
    "        \n",
    "        print(\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BLEU calculation on OpenNMT results\n",
    "predictions_file = \"/Users/alp/phdCloud/playground/OpenNMT-py/heroes_test_v2-pred.txt\"\n",
    "with open(predictions_file) as f:\n",
    "    content = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "openNMT_predictions = [x.strip() for x in content]\n",
    "\n",
    "def openNMT_translation_generator():\n",
    "    for gold, pred in zip(gold_sentence_tokens, openNMT_predictions):\n",
    "        print([gold])\n",
    "        print(pred.split(\" \"))\n",
    "        yield [gold], pred.split(\" \")\n",
    "        \n",
    "openNMT_bleu, sentence_count = compute_bleu(openNMT_translation_generator(), max_order=4, smooth=False)\n",
    "\n",
    "print(\"Evaluated %i samples.\"%sentence_count)\n",
    "print(\"BLEU: \", openNMT_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create text translation data from compiled heroes data\n",
    "output_file = \"/Users/alp/phdCloud/playground/punkHeroes/out_heroes_v1/es_goldpuncd.txt\"\n",
    "\n",
    "input_lang.punctuation_level = 2\n",
    "output_lang.punctuation_level = 2\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    for in_sentence_tokens, _ , out_sentence_tokens, _, _, _ in audio_data_generator(AUDIO_TEST_DATA_PATH, input_lang, output_lang, n_prosody_params, input_prosody_params, output_prosody_params):\n",
    "        #to write tab separated en-es\n",
    "        #f.write(\"%s\\t%s\\n\"%(readable_from_tokens(in_sentence_tokens), readable_from_tokens(out_sentence_tokens)))\n",
    "        #to write only en\n",
    "        #f.write(\"%s\\n\"%(readable_from_tokens(in_sentence_tokens)))\n",
    "        #to write only es\n",
    "        f.write(\"%s\\n\"%(readable_from_tokens(out_sentence_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BLEU calculation from already translated text files\n",
    "gold_file = \"/Users/alp/phdCloud/playground/punkHeroes/out_heroes_v1/es_goldpuncd.txt\"\n",
    "predictions_file = \"/Users/alp/phdCloud/playground/punkHeroes/out_heroes_v1/translated/en_punkProsed_ted_w_transProsed_5mmheroes_unpuncdinput_v1testset.txt\"\n",
    "\n",
    "def textfile_translation_generator(gold_file, predictions_file):\n",
    "    gold_sentences = []\n",
    "    predicted_sentences = []\n",
    "    with open(gold_file, 'r') as f:\n",
    "        for line in f:\n",
    "            gold_sentences.append(line.strip().split(\" \"))\n",
    "    with open(predictions_file, 'r') as f:\n",
    "        for line in f:\n",
    "            predicted_sentences.append(line.strip().split(\" \"))\n",
    "    for gold, pred in zip(gold_sentences, predicted_sentences):       \n",
    "        yield [gold], pred\n",
    "        \n",
    "bleu, sentence_count = compute_bleu(textfile_translation_generator(gold_file, predictions_file), max_order=4, smooth=False)\n",
    "\n",
    "print(\"Evaluated %i samples.\"%sentence_count)\n",
    "print(\"BLEU: \", bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize text models COPY\n",
    "text_encoder_path = 'models/5mmheroes_puncdinput_encoder.model'\n",
    "text_decoder_path = 'models/5mmheroes_puncdinput_decoder.model'\n",
    "\n",
    "text_encoder = GenericEncoder(input_lang.vocabulary_size, hidden_size, input_lang.get_weights_matrix(), n_layers)\n",
    "text_decoder = LuongAttnDecoderRNN(attn_model, hidden_size, output_lang.get_weights_matrix(), output_lang.vocabulary_size, n_layers, input_feed=config['DECODER_INPUT_FEED'])\n",
    "load_model(text_encoder, text_decoder, text_encoder_path, text_decoder_path, options.gpu2cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Transprosing text files\n",
    "input_file = \"/Users/alp/phdCloud/playground/punkHeroes/out_heroes_v1/en_punkProsed_ted_w.txt\"\n",
    "gold_file = \"/Users/alp/phdCloud/playground/punkHeroes/out_heroes_v1/es_goldpuncd.txt\"\n",
    "output_file = \"/Users/alp/phdCloud/playground/punkHeroes/out_heroes_v1/translated/en_punkProsed_ted_w_transProsed_5mmheroes_unpuncdinput_v1testset.txt\"\n",
    "\n",
    "stop_at = -1\n",
    "report = False\n",
    "\n",
    "gold_sentences = []\n",
    "predicted_sentences = []\n",
    "input_sentences = []\n",
    "\n",
    "#read files\n",
    "with open(gold_file, 'r') as f:\n",
    "    for line in f:\n",
    "        gold_sentences.append(line.strip().split(\" \"))\n",
    "with open(input_file, 'r') as f:\n",
    "    for line in f:\n",
    "        input_sentences.append(line.strip().split(\" \"))\n",
    "#translate\n",
    "count = 0\n",
    "for in_sentence_tokens, gold_tokens in zip(input_sentences, gold_sentences):\n",
    "    translation_tokens, _ = evaluate_text(in_sentence_tokens, input_lang, output_lang, text_encoder, text_decoder, max_seq_length)\n",
    "    predicted_sentences.append(translation_tokens)\n",
    "    if report:\n",
    "        print(\"> %s\"%(readable_from_tokens(in_sentence_tokens)))\n",
    "        print(\"= %s\"%(readable_from_tokens(gold_tokens)))\n",
    "        print(\"< %s\"%readable_from_tokens(translation_tokens[:-1]))\n",
    "        print(\"---\")\n",
    "    #yield [gold_tokens], translation_tokens\n",
    "\n",
    "    count += 1\n",
    "    if count == stop_at:\n",
    "        break\n",
    "    if count % 100 == 0:\n",
    "        print(count)\n",
    "            \n",
    "#store translations in a text file\n",
    "with open(output_file, 'w') as f:\n",
    "    for token_index, script_tokens in enumerate(predicted_sentences):\n",
    "        f.write(\"%s\\n\" % ' '.join(script_tokens[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
