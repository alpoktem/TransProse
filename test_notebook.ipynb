{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from utils import *\n",
    "from models import *\n",
    "import yaml\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Options:\n",
    "    def __init__(self):\n",
    "        self.model_name = 'alp'\n",
    "\n",
    "options = Options()\n",
    "options.output_file = 'test_output/reapos_test_text.txt'\n",
    "options.params_file = 'params.yaml'\n",
    "options.use_cuda = False\n",
    "options.use_validation = True\n",
    "options.gpu2cpu = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-18 12:00:37,725 : INFO : loading Word2Vec object from /Users/alp/Documents/Corpora/OpenSubtitles2018/w2v/reapos_min5_heroes/w2v_en_heroes.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use cuda: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-18 12:00:38,639 : INFO : loading wv recursively from /Users/alp/Documents/Corpora/OpenSubtitles2018/w2v/reapos_min5_heroes/w2v_en_heroes.model.wv.* with mmap=None\n",
      "2018-07-18 12:00:38,643 : INFO : loading vectors from /Users/alp/Documents/Corpora/OpenSubtitles2018/w2v/reapos_min5_heroes/w2v_en_heroes.model.wv.vectors.npy with mmap=None\n",
      "2018-07-18 12:00:38,766 : INFO : setting ignored attribute vectors_norm to None\n",
      "2018-07-18 12:00:38,771 : INFO : loading vocabulary recursively from /Users/alp/Documents/Corpora/OpenSubtitles2018/w2v/reapos_min5_heroes/w2v_en_heroes.model.vocabulary.* with mmap=None\n",
      "2018-07-18 12:00:38,776 : INFO : loading trainables recursively from /Users/alp/Documents/Corpora/OpenSubtitles2018/w2v/reapos_min5_heroes/w2v_en_heroes.model.trainables.* with mmap=None\n",
      "2018-07-18 12:00:38,780 : INFO : loading syn1neg from /Users/alp/Documents/Corpora/OpenSubtitles2018/w2v/reapos_min5_heroes/w2v_en_heroes.model.trainables.syn1neg.npy with mmap=None\n",
      "2018-07-18 12:00:38,921 : INFO : setting ignored attribute cum_table to None\n",
      "2018-07-18 12:00:38,922 : INFO : loaded /Users/alp/Documents/Corpora/OpenSubtitles2018/w2v/reapos_min5_heroes/w2v_en_heroes.model\n",
      "2018-07-18 12:00:39,493 : INFO : loading Word2Vec object from /Users/alp/Documents/Corpora/OpenSubtitles2018/w2v/reapos_min5_heroes/w2v_es_heroes.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en Vocabulary size: 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-18 12:00:40,811 : INFO : loading wv recursively from /Users/alp/Documents/Corpora/OpenSubtitles2018/w2v/reapos_min5_heroes/w2v_es_heroes.model.wv.* with mmap=None\n",
      "2018-07-18 12:00:40,812 : INFO : loading vectors from /Users/alp/Documents/Corpora/OpenSubtitles2018/w2v/reapos_min5_heroes/w2v_es_heroes.model.wv.vectors.npy with mmap=None\n",
      "2018-07-18 12:00:41,044 : INFO : setting ignored attribute vectors_norm to None\n",
      "2018-07-18 12:00:41,048 : INFO : loading vocabulary recursively from /Users/alp/Documents/Corpora/OpenSubtitles2018/w2v/reapos_min5_heroes/w2v_es_heroes.model.vocabulary.* with mmap=None\n",
      "2018-07-18 12:00:41,049 : INFO : loading trainables recursively from /Users/alp/Documents/Corpora/OpenSubtitles2018/w2v/reapos_min5_heroes/w2v_es_heroes.model.trainables.* with mmap=None\n",
      "2018-07-18 12:00:41,050 : INFO : loading syn1neg from /Users/alp/Documents/Corpora/OpenSubtitles2018/w2v/reapos_min5_heroes/w2v_es_heroes.model.trainables.syn1neg.npy with mmap=None\n",
      "2018-07-18 12:00:41,474 : INFO : setting ignored attribute cum_table to None\n",
      "2018-07-18 12:00:41,475 : INFO : loaded /Users/alp/Documents/Corpora/OpenSubtitles2018/w2v/reapos_min5_heroes/w2v_es_heroes.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es Vocabulary size: 30000\n"
     ]
    }
   ],
   "source": [
    "#LOAD CONFIGURATIONS AND LANGUAGES\n",
    "USE_CUDA = options.use_cuda\n",
    "print(\"Use cuda: %s\" %USE_CUDA)\n",
    "\n",
    "try:\n",
    "    with open(options.params_file, 'r') as ymlfile:\n",
    "        config = yaml.load(ymlfile)\n",
    "except:\n",
    "    sys.exit(\"Parameters file missing\")\n",
    "\n",
    "#Setup languages\n",
    "INPUT_LANG_CODE = config['INPUT_LANG']\n",
    "OUTPUT_LANG_CODE = config['OUTPUT_LANG']\n",
    "\n",
    "if INPUT_LANG_CODE == 'en' and OUTPUT_LANG_CODE == 'es':\n",
    "    lang_en = input_lang = Lang(INPUT_LANG_CODE, config[\"W2V_EN_PATH\"], config[\"DICT_EN_PATH\"], omit_punctuation=config[\"INPUT_LANG_OMIT_PUNC\"])\n",
    "    lang_es = output_lang = Lang(OUTPUT_LANG_CODE, config[\"W2V_ES_PATH\"], config[\"DICT_ES_PATH\"], omit_punctuation=config[\"OUTPUT_LANG_OMIT_PUNC\"])\n",
    "elif INPUT_LANG_CODE == 'es' and OUTPUT_LANG_CODE == 'en':\n",
    "    lang_es = input_lang = Lang(INPUT_LANG_CODE, config[\"W2V_ES_PATH\"], config[\"DICT_ES_PATH\"], omit_punctuation=config[\"INPUT_LANG_OMIT_PUNC\"])\n",
    "    lang_en = output_lang = Lang(OUTPUT_LANG_CODE, config[\"W2V_EN_PATH\"], config[\"DICT_EN_PATH\"], omit_punctuation=config[\"OUTPUT_LANG_OMIT_PUNC\"])\n",
    "\n",
    "input_prosody_params = config['INPUT_PROSODY']\n",
    "if input_prosody_params == None:\n",
    "    input_prosody_params = []\n",
    "output_prosody_params = config['OUTPUT_PROSODY']\n",
    "if output_prosody_params == None:\n",
    "    output_prosody_params = []    \n",
    "    \n",
    "#NETWORK CONFIG\n",
    "max_seq_length = int(config['MAX_SEQ_LENGTH'])\n",
    "n_prosody_params = int(config['N_PROSODY_PARAMS'])\n",
    "input_prosody_params = config['INPUT_PROSODY']\n",
    "encoder_type = config['ENCODER_TYPE']\n",
    "attn_model = config['ATTN_MODEL']\n",
    "hidden_size = int(config['HIDDEN_SIZE'])\n",
    "n_layers = int(config['N_LAYERS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD DATASETS    \n",
    "#!!!TESTING ON TRAINING SET!!!\n",
    "AUDIO_TEST_DATA_PATH = config[\"AUDIO_TRAIN_DATA_FILE\"]\n",
    "TEXT_TEST_DATA_PATH = config['TEXT_TEST_DATA_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu2cpu: True\n"
     ]
    }
   ],
   "source": [
    "#Initialize text models\n",
    "text_encoder_path = 'models/reapos_encoder.model'\n",
    "text_decoder_path = 'models/reapos_decoder.model'\n",
    "\n",
    "text_encoder = GenericEncoder(input_lang.vocabulary_size, hidden_size, input_lang.get_weights_matrix(), n_layers)\n",
    "text_decoder = LuongAttnDecoderRNN(attn_model, hidden_size, output_lang.get_weights_matrix(), output_lang.vocabulary_size, n_layers)\n",
    "load_model(text_encoder, text_decoder, text_encoder_path, text_decoder_path, options.gpu2cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu2cpu: True\n"
     ]
    }
   ],
   "source": [
    "#Initialize prosodic models\n",
    "# prosodic_encoder_path = 'models/audio1test_encoder.model'\n",
    "# prosodic_decoder_path = 'models/audio1test_decoder.model'\n",
    "\n",
    "prosodic_encoder_path = 'models/simpleloss_encoder.model'\n",
    "prosodic_decoder_path = 'models/simpleloss_decoder.model'\n",
    "\n",
    "if encoder_type == 'sum':\n",
    "    prosodic_encoder = EncoderRNN_sum(input_lang.vocabulary_size, n_prosody_params, hidden_size, input_lang.get_weights_matrix(), n_layers)\n",
    "elif encoder_type == 'parallel':\n",
    "    prosodic_encoder = EncoderRNN_parallel(input_lang.vocabulary_size, n_prosody_params, hidden_size, input_lang.get_weights_matrix(), n_layers)\n",
    "else:\n",
    "    sys.exit(\"Unrecognized encoder type. Check params file. Exiting...\")\n",
    "prosodic_decoder = ProsodicDecoderRNN(attn_model, hidden_size, output_lang.vocabulary_size, n_layers)\n",
    "\n",
    "load_model(prosodic_encoder, prosodic_decoder, prosodic_encoder_path, prosodic_decoder_path, gpu_to_cpu=options.gpu2cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA GENERATORS\n",
    "def text_data_generator(data_path, input_lang, output_lang, stop_at=-1):\n",
    "    count = 0\n",
    "    with open(data_path,'r') as inputfile:\n",
    "        for line in inputfile:\n",
    "            if not stop_at == -1 and count >= stop_at:\n",
    "                break\n",
    "            pair = [sentence.strip() for sentence in line.split('\\t')]\n",
    "            if input_lang.lang_code == 'en':\n",
    "                in_sentence = pair[0]\n",
    "                out_sentence = pair[1]\n",
    "            elif input_lang.lang_code == 'es':\n",
    "                in_sentence = pair[1]\n",
    "                out_sentence = pair[0]\n",
    "\n",
    "            in_sentence_tokens = in_sentence.lower().split()\n",
    "            out_sentence_tokens = out_sentence.lower().split()\n",
    "\n",
    "            if input_lang.omit_punctuation:\n",
    "                in_sentence_tokens = remove_punc_tokens(in_sentence_tokens)\n",
    "            if output_lang.omit_punctuation:\n",
    "                out_sentence_tokens = remove_punc_tokens(out_sentence_tokens)\n",
    "\n",
    "            count += 1\n",
    "\n",
    "            yield in_sentence_tokens, out_sentence_tokens\n",
    "            \n",
    "\n",
    "def audio_data_generator(data_path, input_lang, output_lang, n_prosody_params, input_prosody_params, output_prosody_params, stop_at = -1):\n",
    "    assert not input_lang == output_lang\n",
    "    audio_data = read_audio_dataset_file(data_path, shuffle=False)\n",
    "\n",
    "    #start generating samples from the proscript links in the data file\n",
    "    count = 0\n",
    "    for segment_data in audio_data:\n",
    "        if not stop_at == -1 and count >= stop_at:\n",
    "            break\n",
    "\n",
    "        es_txt = segment_data[0]\n",
    "        es_csv = segment_data[1]\n",
    "        en_txt = segment_data[2]\n",
    "        en_csv = segment_data[3]\n",
    "\n",
    "        if input_lang.lang_code == 'en' and output_lang.lang_code == 'es':\n",
    "            input_proscript = en_csv\n",
    "            output_proscript = es_csv\n",
    "            #input_transcript = read_text_file(en_txt)\n",
    "            #output_transcript = read_text_file(es_txt)\n",
    "        elif input_lang.lang_code == 'es' and output_lang.lang_code == 'en':\n",
    "            input_proscript = es_csv\n",
    "            output_proscript = en_csv\n",
    "            #input_transcript = read_text_file(es_txt)\n",
    "            #output_transcript = read_text_file(en_txt)\n",
    "\n",
    "        in_sentence_tokens, in_prosody_tokens = read_data_from_proscript(input_proscript, input_lang, n_prosody_params, input_prosody_params, punctuation_as_tokens = not input_lang.omit_punctuation)\n",
    "        out_sentence_tokens, out_prosody_tokens = read_data_from_proscript(output_proscript, output_lang, n_prosody_params, output_prosody_params, punctuation_as_tokens = not output_lang.omit_punctuation)\n",
    "    \n",
    "        yield in_sentence_tokens, in_prosody_tokens, out_sentence_tokens, out_prosody_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#various utilities\n",
    "def print_prosody(prosody):\n",
    "    print(np.array(prosody).transpose())\n",
    "    \n",
    "def print_tokens_with_pause(tokens, pausevals = [], pauseflags=[]):\n",
    "    if pauseflags == [] and not pausevals == []:\n",
    "        pauseflags = flags_from_value(pausevals)\n",
    "        \n",
    "    to_print = \"\"\n",
    "    for i, token in enumerate(tokens):\n",
    "        to_print += token + \" \"\n",
    "        if not pausevals == [] and pauseflags[i]:\n",
    "            to_print += \"[\" + \"{:.2f}\".format(pausevals[i]) + \"]\"\n",
    "            to_print += \" \"\n",
    "            \n",
    "    print(to_print)\n",
    "    return to_print\n",
    "            \n",
    "def flags_from_value(prosody_seq):\n",
    "    return [1 if not feature_value == 0.0 else 0 for feature_value in prosody_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEE TEXT DATA\n",
    "for in_sent, out_sent in text_data_generator(TEXT_TEST_DATA_PATH, input_lang, output_lang):\n",
    "    print(in_sent)\n",
    "    print(out_sent)\n",
    "    exit = input('...')\n",
    "    if exit == 'q':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'friend', 'has', 'a', 'new', 'trick']\n",
      "[25, 263, 114, 8, 177, 1525, 29998]\n",
      "[[ 0.      0.      0.      0.      0.      0.      0.    ]\n",
      " [-2.0687  3.3615  3.0931  1.9758  4.5204  0.      0.    ]\n",
      " [-2.6281  0.4716  1.8355  1.5712  1.0302  0.      0.    ]]\n",
      "['tiene', 'una', 'nueva', 'habilidad', '.']\n",
      "[[ 0.      0.      0.      0.      0.    ]\n",
      " [ 4.3959  5.1889 -1.7019 -2.4889 -2.4889]\n",
      " [ 1.1604  0.9001  0.6358 -1.0409 -1.0409]]\n",
      "...Q\n",
      "['now', 'you', 'can', 'afford', 'the', '65', 'dollars', 'i', 'asked', 'you', 'for']\n",
      "[62, 2, 37, 1582, 4, 6780, 1269, 3, 414, 2, 24, 29998]\n",
      "[[ 0.      0.05    0.      0.      0.      0.      0.      0.      0.\n",
      "   0.06    0.      0.    ]\n",
      " [ 2.7948 -0.1108  1.8794  3.5223  2.8689  2.8689 -1.1989  0.1508 -7.7112\n",
      "  -0.2875 -2.4603  0.    ]\n",
      " [-0.0529  1.6238  0.238   0.238   1.8881 -1.586   0.8057  1.0827 -0.3489\n",
      "  -2.9184 -2.9184  0.    ]]\n",
      "['así', 'podrás', 'darme', 'los', '65', 'dólares', 'que', 'te', 'he', 'pedido', '.']\n",
      "[[ 0.03    0.      0.      0.      0.      0.      0.      0.      0.\n",
      "   0.      0.    ]\n",
      " [-5.2075 -3.9149 -3.6676 -4.4204 -3.3031 -2.7122 -2.4813 -5.3422 -3.3031\n",
      "  -6.3158 -6.3158]\n",
      " [-0.1223  0.1592  0.1592 -0.4084 -0.6994  0.4362 -3.222  -0.4084  1.5019\n",
      "  -1.6029 -1.6029]]\n",
      "...q\n"
     ]
    }
   ],
   "source": [
    "#SEE AUDIO DATA\n",
    "for in_sent, in_pros, out_sent, out_pros in audio_data_generator(AUDIO_TEST_DATA_PATH, input_lang, output_lang, n_prosody_params, input_prosody_params, output_prosody_params):\n",
    "    print(in_sent)\n",
    "    print(indexes_from_tokens(input_lang, in_sent))\n",
    "    in_pros = finalize_prosody_sequence(in_pros)\n",
    "    print_prosody(in_pros)\n",
    "    print(out_sent)\n",
    "    print_prosody(out_pros)\n",
    "    exit = input('...')\n",
    "    if exit == 'q':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUATORS\n",
    "#text -> text\n",
    "def evaluate_text(input_seq_tokens, input_lang, output_lang, encoder, decoder, max_length, USE_CUDA=False):\n",
    "    input_word_seqs = [indexes_from_tokens(input_lang, input_seq_tokens)]\n",
    "    \n",
    "    #make sure sequences are below max_length. \n",
    "    input_word_seqs = limit_seqs_to_max(input_word_seqs, max_length)\n",
    "\n",
    "    input_lengths = [len(input_word_seqs[0])]\n",
    "    input_word_batch = Variable(torch.LongTensor(input_word_seqs)).transpose(0, 1)\n",
    "\n",
    "    if USE_CUDA:\n",
    "        input_word_batch = input_batch.cuda()\n",
    "        input_prosody_batch = input_prosody_batch.cuda()\n",
    "\n",
    "    # Set to not-training mode to disable dropout\n",
    "    encoder.train(False)\n",
    "    decoder.train(False)\n",
    "\n",
    "    # Run through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_word_batch, input_lengths, None)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = Variable(torch.LongTensor([output_lang.token2index(SWT_TOKEN)])) # SOS\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
    "\n",
    "    if USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Store output words and attention states\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length + 1, max_length + 1)\n",
    "\n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs\n",
    "        )\n",
    "        decoder_attentions[di,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "\n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        #ni = topi[0][0]  #old code\n",
    "        ni = topi.item()\n",
    "        if ni == output_lang.token2index(EOS_TOKEN):\n",
    "            decoded_words.append(EOS_TOKEN)\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2token(ni))\n",
    "\n",
    "        # Next input is chosen word\n",
    "        decoder_input = Variable(torch.LongTensor([ni]))\n",
    "        if USE_CUDA: decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Set back to training mode\n",
    "    encoder.train(True)\n",
    "    decoder.train(True)\n",
    "\n",
    "    return decoded_words, decoder_attentions[:di+1, :len(encoder_outputs)]\n",
    "\n",
    "#text+audio -> text+audio\n",
    "#use prosodic encoder/decoder\n",
    "def evaluate_audio(input_seq_tokens, input_prosody_tokens, input_lang, output_lang, encoder, decoder, max_length, USE_CUDA=False):\n",
    "    input_word_seqs = [indexes_from_tokens(input_lang, input_seq_tokens)]\n",
    "    input_prosody_seqs = [finalize_prosody_sequence(input_prosody_tokens)] #put the end token\n",
    "    \n",
    "    #make sure sequences are below max_length. \n",
    "    input_word_seqs = limit_seqs_to_max(input_word_seqs, max_length)\n",
    "    input_prosody_seqs = limit_seqs_to_max(input_prosody_seqs, max_length)\n",
    "\n",
    "    input_lengths = [len(input_word_seqs[0])]\n",
    "    input_word_batch = Variable(torch.LongTensor(input_word_seqs)).transpose(0, 1)\n",
    "    input_prosody_batch = Variable(torch.FloatTensor(input_prosody_seqs)).transpose(0, 1)\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        input_word_batch = input_batch.cuda()\n",
    "        input_prosody_batch = input_prosody_batch.cuda()\n",
    "\n",
    "    # Set to not-training mode to disable dropout\n",
    "    encoder.train(False)\n",
    "    decoder.train(False)\n",
    "\n",
    "    # Run through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_word_batch, input_prosody_batch, input_lengths, None)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_word_input = Variable(torch.LongTensor([output_lang.token2index(SWT_TOKEN)])) # SOS\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
    "\n",
    "    if USE_CUDA:\n",
    "        decoder_word_input = decoder_word_input.cuda()\n",
    "\n",
    "    # Store output words and attention states\n",
    "    decoded_word_seq = []\n",
    "    decoded_pauseflag_seq = []\n",
    "    decoded_pausevalue_seq = []\n",
    "    decoder_attentions = torch.zeros(max_length + 1, max_length + 1)\n",
    "\n",
    "    # Run through decoder\n",
    "    decoder_stop = False\n",
    "    for di in range(max_length):\n",
    "        decoder_output_word, decoder_output_pauseflag, decoder_output_pausevalue, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_word_input, decoder_hidden, encoder_outputs\n",
    "        )\n",
    "        decoder_attentions[di,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "            \n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_output_word.data.topk(1)\n",
    "        ni_word = topi.item()\n",
    "        if ni_word == output_lang.token2index(EOS_TOKEN):\n",
    "            decoded_word_seq.append(EOS_TOKEN)\n",
    "            decoder_stop = True\n",
    "        else:\n",
    "            decoded_word_seq.append(output_lang.index2token(ni_word))\n",
    "            \n",
    "        # Look at pauseflag output\n",
    "        topv, topi = decoder_output_pauseflag.data.topk(1)\n",
    "        ni_pauseflag = topi.item()\n",
    "        decoded_pauseflag_seq.append(ni_pauseflag)\n",
    "        \n",
    "        # Look at pauseval output\n",
    "        predicted_pausevalue = decoder_output_pausevalue.item()\n",
    "        decoded_pausevalue_seq.append(predicted_pausevalue)\n",
    "\n",
    "        # Next input is chosen word\n",
    "        if decoder_stop:\n",
    "            break\n",
    "        else:\n",
    "            decoder_word_input = Variable(torch.LongTensor([ni_word]))\n",
    "            if USE_CUDA: decoder_word_input = decoder_word_input.cuda()\n",
    "\n",
    "    # Set back to training mode\n",
    "    encoder.train(True)\n",
    "    decoder.train(True)\n",
    "\n",
    "    return decoded_word_seq, decoded_pauseflag_seq, decoded_pausevalue_seq, decoder_attentions[:di+1, :len(encoder_outputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text+audio -> text+audio\n",
    "#use prosodic encoder/decoder with output forcing\n",
    "def evaluate_audio_force(input_seq_tokens, input_prosody_tokens, out_gold_sentence_tokens, input_lang, output_lang, encoder, decoder, max_length, USE_CUDA=False):\n",
    "    input_word_seqs = [indexes_from_tokens(input_lang, input_seq_tokens)]\n",
    "    output_word_seqs = [indexes_from_tokens(output_lang, out_gold_sentence_tokens)]\n",
    "    input_prosody_seqs = [finalize_prosody_sequence(input_prosody_tokens)] #put the end token\n",
    "        \n",
    "    #make sure sequences are below max_length. \n",
    "    input_word_seqs = limit_seqs_to_max(input_word_seqs, max_length)\n",
    "    output_word_seqs = limit_seqs_to_max(output_word_seqs, max_length)\n",
    "    input_prosody_seqs = limit_seqs_to_max(input_prosody_seqs, max_length)\n",
    "\n",
    "    input_lengths = [len(input_word_seqs[0])]\n",
    "    input_word_batch = Variable(torch.LongTensor(input_word_seqs)).transpose(0, 1)\n",
    "    input_prosody_batch = Variable(torch.FloatTensor(input_prosody_seqs)).transpose(0, 1)\n",
    "    output_word_batch = Variable(torch.LongTensor(output_word_seqs)).transpose(0, 1)\n",
    "    \n",
    "    output_length = len(output_word_seqs[0])\n",
    "    \n",
    "    if USE_CUDA:\n",
    "        input_word_batch = input_batch.cuda()\n",
    "        input_prosody_batch = input_prosody_batch.cuda()\n",
    "        output_word_batch = output_word_batch.cuda()\n",
    "\n",
    "    # Set to not-training mode to disable dropout\n",
    "    encoder.train(False)\n",
    "    decoder.train(False)\n",
    "\n",
    "    # Run through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_word_batch, input_prosody_batch, input_lengths, None)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_word_input = Variable(torch.LongTensor([output_lang.token2index(SWT_TOKEN)])) # SOS\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
    "\n",
    "    if USE_CUDA:\n",
    "        decoder_word_input = decoder_word_input.cuda()\n",
    "\n",
    "    # Store output words and attention states\n",
    "    decoded_word_seq = []\n",
    "    decoded_pauseflag_seq = []\n",
    "    decoded_pausevalue_seq = []\n",
    "    decoder_attentions = torch.zeros(max_length + 1, max_length + 1)\n",
    "\n",
    "    # Run through decoder\n",
    "    for t in range(output_length):\n",
    "        decoder_output_word, decoder_output_pauseflag, decoder_output_pausevalue, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_word_input, decoder_hidden, encoder_outputs\n",
    "        )\n",
    "        decoder_attentions[t,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "            \n",
    "        # Choose top word from output\n",
    "        topv, topi = decoder_output_word.data.topk(1)\n",
    "        ni_word = topi.item()\n",
    "        decoded_word_seq.append(output_lang.index2token(ni_word))\n",
    "            \n",
    "        # Look at pauseflag output\n",
    "        topv, topi = decoder_output_pauseflag.data.topk(1)\n",
    "        ni_pauseflag = topi.item()\n",
    "        decoded_pauseflag_seq.append(ni_pauseflag)\n",
    "        \n",
    "        # Look at pauseval output\n",
    "        predicted_pausevalue = decoder_output_pausevalue.item()\n",
    "        decoded_pausevalue_seq.append(predicted_pausevalue)\n",
    "\n",
    "        # Next input is chosen word\n",
    "        decoder_word_input = output_word_batch[t]\n",
    "        if USE_CUDA: decoder_word_input = decoder_word_input.cuda()\n",
    "            \n",
    "\n",
    "    # Set back to training mode\n",
    "    encoder.train(True)\n",
    "    decoder.train(True)\n",
    "\n",
    "    return decoded_word_seq, decoded_pauseflag_seq, decoded_pausevalue_seq, decoder_attentions[:t+1, :len(encoder_outputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text -> text evaluator test\n",
    "input_sentence = \"oh this is a terrible disaster this shouldn 't have never happened\"\n",
    "input_seq_tokens = input_sentence.split()\n",
    "decoded_words, _ = evaluate_text(input_seq_tokens, input_lang, output_lang, text_encoder, text_decoder, max_seq_length)\n",
    "print(decoded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = audio_data_generator(AUDIO_TEST_DATA_PATH, input_lang, output_lang, n_prosody_params, input_prosody_params, output_prosody_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN\n",
      "my friend has a new trick \n",
      "GT\n",
      "tiene una nueva habilidad . \n",
      "OUT PROSODY\n",
      "mi amigo es un truco de nuevo . END \n",
      "OUT FORCE\n",
      "mi un compañera amigo . END \n",
      "OUT TEXT\n",
      "mi amigo tiene un nuevo truco . END \n",
      "======================================================================\n",
      "IN\n",
      "now you [0.05] can afford the 65 dollars i asked you [0.06] for \n",
      "GT\n",
      "así [0.03] podrás darme los 65 dólares que te he pedido . \n",
      "OUT PROSODY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alp/extSW/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:6: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n",
      "/Users/alp/extSW/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:12: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿ no puedes dar a 100 dólares ? te pedí que te pedí . END \n",
      "OUT FORCE\n",
      "¿ se dar el 65 dólares . te pedí pedido . END \n",
      "OUT TEXT\n",
      "a las costumbres , te lo pedí por la borda . END \n",
      "======================================================================\n",
      "IN\n",
      "day number five without the meds \n",
      "GT\n",
      "cinco días sin medicinas . \n",
      "OUT PROSODY\n",
      "el número 5 sin los medicación . END \n",
      "OUT FORCE\n",
      "el días sin los . END \n",
      "OUT TEXT\n",
      "el día , el número 5 sin la medicación . END \n",
      "======================================================================\n",
      "IN\n",
      "he was my friend too [0.03] 400 years ago \n",
      "GT\n",
      "también lo era mío [0.31] hace 400 años . \n",
      "OUT PROSODY\n",
      "era mi amigo , un [0.23] amigo de uno . END \n",
      "OUT FORCE\n",
      "era era era , , mucho años . END \n",
      "OUT TEXT\n",
      "era mi amigo , hace unos años , por aquí . END \n",
      "======================================================================\n",
      "IN\n",
      "she 's from america \n",
      "GT\n",
      "es de américa . \n",
      "OUT PROSODY\n",
      "es de el estados unidos . END \n",
      "OUT FORCE\n",
      "es de el . END \n",
      "OUT TEXT\n",
      "es de américa . END \n",
      "======================================================================\n",
      "IN\n",
      "no no not that thing [0.45] the other thing i 'll let you know \n",
      "GT\n",
      "no , no . eso no [0.39] . la otra cosa [0.04] . ya te [0.03] cuento . \n",
      "OUT PROSODY\n",
      "no , no , no , no , no , no , no , no , no , no , no , no , no , no , no , no , no , no , no , no , \n",
      "OUT FORCE\n",
      "no , no , no no , no cosa [0.17] cosa [0.10] , la lo lo . END \n",
      "OUT TEXT\n",
      "lo que te diré , no , no , no , no , no , no , no , no , no , no , no , no , no , no , no , no , no , no \n",
      "======================================================================\n",
      "IN\n",
      "i don 't know \n",
      "GT\n",
      "no lo sé . \n",
      "OUT PROSODY\n",
      "no lo sé . END \n",
      "OUT FORCE\n",
      "no lo sé . END \n",
      "OUT TEXT\n",
      ", no lo sé . END \n",
      "======================================================================\n",
      "IN\n",
      "unique [0.38] an ability [0.04] doesn 't have to [0.03] be a burden maya \n",
      "GT\n",
      "único [0.22] . un poder no tiene por qué ser una carga , maya . \n",
      "OUT PROSODY\n",
      "es un poder que no tiene que ser una carga , maya . END \n",
      "OUT FORCE\n",
      "es que no poder no tiene que qué ser un carga , maya . END \n",
      "OUT TEXT\n",
      "un poco de habilidad no tiene que ser un problema , ¿ y sí ? END \n",
      "======================================================================\n",
      "IN\n",
      "just [0.39] make it fast \n",
      "GT\n",
      "pero [0.34] que sea rápido . \n",
      "OUT PROSODY\n",
      "- ¿ [0.35] va [0.27] a hacer el de la guerra ? END \n",
      "OUT FORCE\n",
      "- si sea un . END \n",
      "OUT TEXT\n",
      ", rápido , rápido . END \n",
      "======================================================================\n",
      "IN\n",
      "you have to remember something [0.04] anything [0.26] a name a face \n",
      "GT\n",
      "tienes que recordar algo , lo que sea [0.13] , un nombre [0.05] , una cara ... \n",
      "OUT PROSODY\n",
      "tienes [0.18] que recordar algo , un nombre , un nombre . END \n",
      "OUT FORCE\n",
      "tienes [0.18] que recordar algo , un que un un un nombre , un cara . END \n",
      "OUT TEXT\n",
      "que recuerde algo , una cara , una cara , una cara , la cara ... END \n",
      "...q\n"
     ]
    }
   ],
   "source": [
    "#Text+prosody -> text+prosody on audio data\n",
    "print_every = 10\n",
    "print_count = 0\n",
    "for in_sentence_tokens, in_prosody_tokens , out_sentence_tokens, out_prosody_tokens in gen:\n",
    "    print_count += 1\n",
    "    print(\"IN\")\n",
    "    print_tokens_with_pause(in_sentence_tokens, in_prosody_tokens[:,0])\n",
    "    print(\"GT\")\n",
    "    print_tokens_with_pause(out_sentence_tokens, out_prosody_tokens[:,0])\n",
    "    \n",
    "    print(\"OUT PROSODY\")\n",
    "    translation_tokens, pauseflag_tokens, pausevalue_tokens, _ = evaluate_audio(in_sentence_tokens, in_prosody_tokens, input_lang, output_lang, prosodic_encoder, prosodic_decoder, max_seq_length)\n",
    "    print_tokens_with_pause(translation_tokens, pausevalue_tokens, pauseflag_tokens)\n",
    "    print(\"OUT FORCE\")\n",
    "    translation_tokens, pauseflag_tokens, pausevalue_tokens, _ = evaluate_audio_force(in_sentence_tokens, in_prosody_tokens, out_sentence_tokens, input_lang, output_lang, prosodic_encoder, prosodic_decoder, max_seq_length)\n",
    "    print_tokens_with_pause(translation_tokens, pausevalue_tokens, pauseflag_tokens)\n",
    "    print(\"OUT TEXT\")\n",
    "    translation_tokens, _ = evaluate_text(in_sentence_tokens, input_lang, output_lang, text_encoder, text_decoder, max_seq_length)\n",
    "    print_tokens_with_pause(translation_tokens)\n",
    "    \n",
    "    if print_count % print_every == 0:\n",
    "        inp = input(\"...\")\n",
    "        if inp == 'q':\n",
    "            break\n",
    "    print(\"======================================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text -> text on text data\n",
    "def text_set_translation_generator(stop_at = -1, report=False):\n",
    "    for in_sentence_tokens, out_sentence_tokens in text_data_generator(TEXT_TEST_DATA_PATH, input_lang, output_lang, stop_at):\n",
    "        translation_tokens, _ = evaluate_text(in_sentence_tokens, input_lang, output_lang, text_encoder, text_decoder, max_seq_length)\n",
    "        if report:\n",
    "            print(\"> %s\"%(readable_from_tokens(in_sentence_tokens)))\n",
    "            print(\"= %s\"%(readable_from_tokens(out_sentence_tokens)))\n",
    "            print(\"< %s\"%readable_from_tokens(translation_tokens[:-1]))\n",
    "            print(\"---\")\n",
    "        \n",
    "        yield [out_sentence_tokens], translation_tokens[:-1]\n",
    "        \n",
    "testing_set_bleu, sentence_count = compute_bleu(text_set_translation_generator(stop_at=100, report=True), max_order=4, smooth=False)\n",
    "\n",
    "print(\"Evaluated %i samples.\"%sentence_count)\n",
    "print(\"BLEU: \", testing_set_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "1\n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unknown (en): tubettes\n",
      "Unknown (en): petrellis\n",
      "Unknown (en): lempiras\n",
      "Unknown (en): zeitlan\n",
      "Unknown (en): powerwalk\n",
      "Unknown (en): lempiras\n",
      "Unknown (en): cholinergic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "1\n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unknown (en): zeitlan\n",
      "Unknown (en): pwen\n",
      "Unknown (en): rasmalai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "1\n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unknown (en): unextraordinary\n",
      "Unknown (en): for40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "1\n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unknown (en): homicidio\n",
      "Unknown (en): showboated\n",
      "Unknown (en): annapura\n",
      "Unknown (en): annapura\n",
      "Unknown (en): conﬁned\n",
      "Unknown (en): lllllom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "1\n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unknown (en): dopamines\n",
      "Unknown (en): canmore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated 6141 samples.\n",
      "BLEU:  0.11291731515763413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unknown (en): m.0\n"
     ]
    }
   ],
   "source": [
    "#Text -> text on audio data\n",
    "def audio_set_text_translation_generator(stop_at = -1, report=False):\n",
    "    for in_sentence_tokens, _ , out_sentence_tokens, _ in audio_data_generator(AUDIO_TEST_DATA_PATH, input_lang, output_lang, n_prosody_params, input_prosody_params, output_prosody_params):\n",
    "        translation_tokens, _ = evaluate_text(in_sentence_tokens, input_lang, output_lang, text_encoder, text_decoder, max_seq_length)\n",
    "        if report:\n",
    "            print(\"> %s\"%(readable_from_tokens(in_sentence_tokens)))\n",
    "            print(\"= %s\"%(readable_from_tokens(out_sentence_tokens)))\n",
    "            print(\"< %s\"%readable_from_tokens(translation_tokens[:-1]))\n",
    "            print(\"---\")\n",
    "        \n",
    "        yield [out_sentence_tokens], translation_tokens[:-1]\n",
    "        \n",
    "testing_set_bleu, sentence_count = compute_bleu(audio_set_text_translation_generator(), max_order=4, smooth=False)\n",
    "\n",
    "print(\"Evaluated %i samples.\"%sentence_count)\n",
    "print(\"BLEU: \", testing_set_bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
